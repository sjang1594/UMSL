{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-Phase6.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "snWRiGMXM6bi",
        "jQw2XjfEX13z",
        "IPKkqk_VPCoI"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej7c9R6UKC5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "from PIL import Image\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITEPGLjrKIu5",
        "colab_type": "code",
        "outputId": "c03c95fc-d696-4c4e-94df-dcc40d4d0838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir = os.path.join(\"/content/drive/My Drive/Face_Data\")\n",
        "!ls \"/content/drive/My Drive/Face_Data\"\n",
        "\n",
        "Train_dir = base_dir + '/Train/'\n",
        "Test_dir = base_dir + '/Test/'\n",
        "Valid_dir = base_dir + \"/Validation/\"\n",
        "\n",
        "nb_train_samples = sum([len(files) for _, _, files in os.walk(Train_dir)])\n",
        "nb_validation_samples = sum([len(files) for _, _, files in os.walk(Valid_dir)])\n",
        "nb_test_samples = sum([len(files) for _, _, files in os.walk(Test_dir)])\n",
        "total_nb_samples = nb_train_samples + nb_validation_samples + nb_test_samples\n",
        "\n",
        "print(' - # of trained samples: ', nb_train_samples, '\\n - # of validation samples: ', nb_validation_samples,\n",
        "      '\\n - # of test samples: ', nb_test_samples,\n",
        "       '\\n - total # of samples: ', total_nb_samples, '\\n - train ratio:', round(nb_train_samples/total_nb_samples*100, 2),\n",
        "      '\\n - validation ratio:', round(nb_validation_samples/total_nb_samples*100, 2),\n",
        "      '\\n - test ratio:', round(nb_test_samples/total_nb_samples*100, 2),)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Test  Train  Validation\n",
            " - # of trained samples:  788 \n",
            " - # of validation samples:  181 \n",
            " - # of test samples:  171 \n",
            " - total # of samples:  1140 \n",
            " - train ratio: 69.12 \n",
            " - validation ratio: 15.88 \n",
            " - test ratio: 15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEStzk4OKPZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['Dumbledore', 'Hagrid', 'Harry', 'Hermione', 'Malfoy', 'Ron']\n",
        "\n",
        "class_names_label = {class_name : i for i, class_name in enumerate(class_names)}\n",
        "nb_classes = len(class_names)\n",
        "\n",
        "IMAGE_SIZE = (90, 140)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y2uktFI2pGz",
        "colab_type": "text"
      },
      "source": [
        "## **Load the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W75P9XB7KVv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "  datasets = [Train_dir, Valid_dir, Test_dir]\n",
        "  output = []\n",
        "  \n",
        "  for dataset in datasets:\n",
        "    Images = []\n",
        "    Labels = []\n",
        "\n",
        "    print(\"Loading {}\".format(dataset))\n",
        "\n",
        "    for folder in os.listdir(dataset):\n",
        "      curr_label = class_names_label[folder]\n",
        "\n",
        "      for file in os.listdir(os.path.join(dataset, folder)):\n",
        "        img_path = os.path.join(os.path.join(dataset, folder), file)\n",
        "\n",
        "        curr_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        #Whether or not there is bad file, print that image_path\n",
        "        try:\n",
        "          curr_img = cv2.resize(curr_img, IMAGE_SIZE)\n",
        "        except cv2.error as e:\n",
        "          print(img_path, 'Invalid Frame!')\n",
        "        cv2.waitKey()  \n",
        "\n",
        "        Images.append(curr_img)\n",
        "        Labels.append(curr_label)\n",
        "\n",
        "    Images = np.array(Images)\n",
        "    Labels = np.array(Labels)\n",
        "    output.append((Images, Labels))\n",
        "  return output  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmCdGyY3KXgq",
        "colab_type": "code",
        "outputId": "35a9897c-9b1a-48b3-baa4-e198919daafa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "(train_images, train_labels), (valid_images, valid_labels), (test_images, test_labels) = load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading /content/drive/My Drive/Face_Data/Train/\n",
            "Loading /content/drive/My Drive/Face_Data/Validation/\n",
            "Loading /content/drive/My Drive/Face_Data/Test/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZLcWMICKYuG",
        "colab_type": "code",
        "outputId": "559a39b1-f036-45e1-bb33-497e2fa2642e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "print (\"Number of Training Examples: \" + str(train_labels.shape[0]))\n",
        "print (\"Number of Validation Examples : \" + str(valid_images.shape[0]))\n",
        "print (\"Number of Testing Examples: \" + str(test_labels.shape[0]))\n",
        "print (\"Each image is of size: \" + str(train_images.shape[0:]))\n",
        "\n",
        "print(\"Size of Test image : \" + str(test_images.shape[0:]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Training Examples: 788\n",
            "Number of Validation Examples : 181\n",
            "Number of Testing Examples: 171\n",
            "Each image is of size: (788, 140, 90)\n",
            "Size of Test image : (171, 140, 90)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYgi-3tr2koX",
        "colab_type": "text"
      },
      "source": [
        "## **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYyN3AG7KZmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = train_images.reshape((788, 140, 90, 1))\n",
        "x_valid = valid_images.reshape((181, 140, 90, 1))\n",
        "x_test = test_images.reshape((test_images.shape[0], 140, 90, 1))\n",
        "\n",
        "train_img = x_train / 255.0 \n",
        "valid_img = x_valid / 255.0\n",
        "test_img = x_test / 255.0\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(train_labels)\n",
        "y_valid = tf.keras.utils.to_categorical(valid_labels)\n",
        "y_test = tf.keras.utils.to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snWRiGMXM6bi",
        "colab_type": "text"
      },
      "source": [
        "## **Best Original Model with Augmented Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsajm6k8Kcl_",
        "colab_type": "code",
        "outputId": "a569ca1a-e429-458d-cffb-c9925c186c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=20,\n",
        "                               width_shift_range=0.2,\n",
        "                               height_shift_range=0.2,\n",
        "                               shear_range=0.2,\n",
        "                               zoom_range=0.2,\n",
        "                               horizontal_flip=True,\n",
        "                               rescale=1./255,\n",
        "                               fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(Train_dir,\n",
        "                                                    target_size = (140, 90),\n",
        "                                                    color_mode='grayscale',\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    shuffle=True\n",
        "                                                    )\n",
        "\n",
        "validation_genrator = validation_datagen.flow_from_directory(Valid_dir, \n",
        "                                                   target_size=(140, 90),\n",
        "                                                   color_mode='grayscale',\n",
        "                                                   batch_size = 181,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=True)\n",
        " \n",
        "test_generator = test_datagen.flow_from_directory(Test_dir, \n",
        "                                                  target_size = (140, 90),\n",
        "                                                  color_mode='grayscale',\n",
        "                                                  batch_size = 171 ,\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 788 images belonging to 6 classes.\n",
            "Found 181 images belonging to 6 classes.\n",
            "Found 171 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_CN4gsUM_jm",
        "colab_type": "code",
        "outputId": "c4117176-38b2-42bb-b077-c20f34708305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "K.clear_session()\n",
        "model_data_aug = Sequential()\n",
        "model_data_aug.add( Conv2D(32, (3, 3), activation= 'relu', input_shape = train_img[0, :, :, :].shape))\n",
        "model_data_aug.add(BatchNormalization())\n",
        "model_data_aug.add( Conv2D(32, ( 3, 3 ), activation = 'relu' ) )\n",
        "model_data_aug.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_data_aug.add( Conv2D(32, ( 3, 3 ), activation = 'relu' ) )\n",
        "model_data_aug.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_data_aug.add(Dropout(0.25))\n",
        "model_data_aug.add( Flatten() )\n",
        "model_data_aug.add( Dense(128, activation = 'relu' ) )\n",
        "model_data_aug.add( Dense(6, activation = 'sigmoid' ) )\n",
        "model_data_aug.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 138, 88, 32)       320       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 138, 88, 32)       128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 136, 86, 32)       9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 68, 43, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 66, 41, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 33, 20, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 33, 20, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 21120)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               2703488   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 2,723,206\n",
            "Trainable params: 2,723,142\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MPFSZ-PNA6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_data_aug.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcsiDhQhNL2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_a = ModelCheckpoint(filepath = 'my_best_model.hdf1', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "callback_b = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QMeUOblNN-W",
        "colab_type": "code",
        "outputId": "927e6ff5-3f8a-4672-918a-8d4375d2e735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "history_aug = model_data_aug.fit_generator(train_generator, \n",
        "                                       steps_per_epoch=100,\n",
        "                                       epochs=100,\n",
        "                                       callbacks=[callback_a, callback_b],\n",
        "                                       validation_data=validation_genrator,\n",
        "                                       validation_steps =valid_images.shape[0] / 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-4d262a7bb588>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            " 34/100 [=========>....................] - ETA: 4s - loss: 0.4380 - accuracy: 0.4132"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5W754kmlPld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history_aug.history['accuracy'])\n",
        "plt.plot(history_aug.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_aug.history['loss'])\n",
        "plt.plot(history_aug.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'lower left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEc7MYFXlTrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_loss_aug, validation_acc_aug = model_data_aug.evaluate( valid_img, y_valid )\n",
        "print( 'validation_acc:', validation_acc_aug)\n",
        "\n",
        "validation_loss_aug2, validation_acc_aug2 = model_data_aug.evaluate_generator(validation_genrator, steps=10)\n",
        "print('validation_acc of gen:', validation_acc_aug2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHWLNbfQlYRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss_aug, test_acc_aug = model_data_aug.evaluate_generator(test_generator, steps=30)\n",
        "print('test_acc:', test_acc_aug)\n",
        "\n",
        "test_loss_aug_r, test_acc_aug_r = model_data_aug.evaluate(test_img, y_test, verbose=1)\n",
        "print(test_acc_aug_r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcZ-B0eNlYK-",
        "colab_type": "text"
      },
      "source": [
        "##**VGG16 pre-trained Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4QTg0ldbtQ7",
        "colab_type": "code",
        "outputId": "d092d17e-4454-4301-ccd0-aad709a5e013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen_VGG16 = ImageDataGenerator(rotation_range=20,\n",
        "                               width_shift_range=0.2,\n",
        "                               height_shift_range=0.2,\n",
        "                               shear_range=0.2,\n",
        "                               zoom_range=0.2,\n",
        "                               horizontal_flip=True,\n",
        "                               rescale=1./255,\n",
        "                               fill_mode='nearest')\n",
        "\n",
        "validation_datagen_VGG16 = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen_VGG16 = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator_VGG16 = train_datagen_VGG16.flow_from_directory(Train_dir,\n",
        "                                                    target_size = (140, 90),\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    shuffle=True\n",
        "                                                    )\n",
        "\n",
        "validation_genrator_VGG16 = validation_datagen_VGG16.flow_from_directory(Valid_dir, \n",
        "                                                   target_size=(140, 90),\n",
        "                                                   batch_size = 181,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=True)\n",
        " \n",
        "test_generator_VGG16 = test_datagen_VGG16.flow_from_directory(Test_dir, \n",
        "                                                  target_size = (140, 90),\n",
        "                                                  batch_size = 171,\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 788 images belonging to 6 classes.\n",
            "Found 181 images belonging to 6 classes.\n",
            "Found 171 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTB_6mEINZvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base_vgg16 = VGG16(weights='imagenet', include_top = False, input_shape=(140,90,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyh7PTz7hWaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in conv_base_vgg16.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQw2XjfEX13z",
        "colab_type": "text"
      },
      "source": [
        "## **VGG16 without the Dropout in the last layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MbB9oJovFQE",
        "colab_type": "code",
        "outputId": "41df7596-42b8-4878-920f-c59afb680b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "K.clear_session()\n",
        "vgg16_model = models.Sequential()\n",
        "vgg16_model.add(conv_base_vgg16)\n",
        "vgg16_model.add(layers.Flatten())\n",
        "vgg16_model.add(layers.Dense(256, activation='relu'))\n",
        "vgg16_model.add(layers.Dense(6, activation='sigmoid'))\n",
        "\n",
        "vgg16_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 4, 2, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               1048832   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 1542      \n",
            "=================================================================\n",
            "Total params: 15,765,062\n",
            "Trainable params: 1,050,374\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPRBgPNtN0_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_a = ModelCheckpoint(filepath = 'my_best_model.hdf1', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "callback_b = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFKU_ZIyEGSB",
        "colab_type": "code",
        "outputId": "40924287-7098-45e4-bc19-535a3c52ade1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vgg16_model.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = vgg16_model.fit_generator(train_generator_VGG16, \n",
        "                                    steps_per_epoch=100,\n",
        "                                    epochs=100,\n",
        "                                    callbacks=[callback_a, callback_b],\n",
        "                                    validation_data=validation_genrator_VGG16,\n",
        "                                    validation_steps=valid_images.shape[0] / 10\n",
        "                                  )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-03fc85c6e4ad>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.6741\n",
            "Epoch 00001: val_loss improved from inf to 0.17425, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.2720 - accuracy: 0.6741 - val_loss: 0.1742 - val_accuracy: 0.7956\n",
            "Epoch 2/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1562 - accuracy: 0.8384\n",
            "Epoch 00002: val_loss improved from 0.17425 to 0.15853, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.1553 - accuracy: 0.8391 - val_loss: 0.1585 - val_accuracy: 0.8177\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.8644\n",
            "Epoch 00003: val_loss improved from 0.15853 to 0.09263, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.1296 - accuracy: 0.8644 - val_loss: 0.0926 - val_accuracy: 0.9006\n",
            "Epoch 4/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1186 - accuracy: 0.8793\n",
            "Epoch 00004: val_loss improved from 0.09263 to 0.07035, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.1185 - accuracy: 0.8793 - val_loss: 0.0703 - val_accuracy: 0.9613\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.8927\n",
            "Epoch 00005: val_loss improved from 0.07035 to 0.06776, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.1068 - accuracy: 0.8927 - val_loss: 0.0678 - val_accuracy: 0.9448\n",
            "Epoch 6/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.9049\n",
            "Epoch 00006: val_loss did not improve from 0.06776\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.0927 - accuracy: 0.9053 - val_loss: 0.0813 - val_accuracy: 0.9282\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9211\n",
            "Epoch 00007: val_loss did not improve from 0.06776\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.0857 - accuracy: 0.9211 - val_loss: 0.0755 - val_accuracy: 0.9392\n",
            "Epoch 8/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9167\n",
            "Epoch 00008: val_loss improved from 0.06776 to 0.06498, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.0794 - accuracy: 0.9165 - val_loss: 0.0650 - val_accuracy: 0.9448\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9372\n",
            "Epoch 00009: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.0677 - accuracy: 0.9372 - val_loss: 0.0683 - val_accuracy: 0.9282\n",
            "Epoch 10/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0726 - accuracy: 0.9274\n",
            "Epoch 00010: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.0722 - accuracy: 0.9277 - val_loss: 0.0791 - val_accuracy: 0.9282\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9372\n",
            "Epoch 00011: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.0674 - accuracy: 0.9372 - val_loss: 0.0718 - val_accuracy: 0.9282\n",
            "Epoch 12/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0599 - accuracy: 0.9402\n",
            "Epoch 00012: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.0599 - accuracy: 0.9404 - val_loss: 0.0844 - val_accuracy: 0.9061\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9388\n",
            "Epoch 00013: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.0597 - accuracy: 0.9388 - val_loss: 0.0658 - val_accuracy: 0.9282\n",
            "Epoch 14/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 0.9438\n",
            "Epoch 00014: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0613 - accuracy: 0.9440 - val_loss: 0.0703 - val_accuracy: 0.9337\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9367\n",
            "Epoch 00015: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0596 - accuracy: 0.9367 - val_loss: 0.0762 - val_accuracy: 0.9282\n",
            "Epoch 16/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 0.9443\n",
            "Epoch 00016: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0604 - accuracy: 0.9445 - val_loss: 0.0662 - val_accuracy: 0.9282\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9514\n",
            "Epoch 00017: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.0522 - accuracy: 0.9514 - val_loss: 0.0744 - val_accuracy: 0.9392\n",
            "Epoch 18/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.9504\n",
            "Epoch 00018: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0474 - accuracy: 0.9506 - val_loss: 0.0661 - val_accuracy: 0.9392\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9489\n",
            "Epoch 00019: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0485 - accuracy: 0.9489 - val_loss: 0.0865 - val_accuracy: 0.9282\n",
            "Epoch 20/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9499\n",
            "Epoch 00020: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0492 - accuracy: 0.9501 - val_loss: 0.0914 - val_accuracy: 0.9227\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9534\n",
            "Epoch 00021: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.0497 - accuracy: 0.9534 - val_loss: 0.0863 - val_accuracy: 0.9227\n",
            "Epoch 22/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9560\n",
            "Epoch 00022: val_loss did not improve from 0.06498\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0443 - accuracy: 0.9562 - val_loss: 0.1109 - val_accuracy: 0.8950\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9529\n",
            "Epoch 00023: val_loss improved from 0.06498 to 0.05936, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.0485 - accuracy: 0.9529 - val_loss: 0.0594 - val_accuracy: 0.9448\n",
            "Epoch 24/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.9596\n",
            "Epoch 00024: val_loss improved from 0.05936 to 0.05587, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.0498 - accuracy: 0.9598 - val_loss: 0.0559 - val_accuracy: 0.9613\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9524\n",
            "Epoch 00025: val_loss did not improve from 0.05587\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.0439 - accuracy: 0.9524 - val_loss: 0.0875 - val_accuracy: 0.9171\n",
            "Epoch 26/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9652\n",
            "Epoch 00026: val_loss did not improve from 0.05587\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.0397 - accuracy: 0.9654 - val_loss: 0.0700 - val_accuracy: 0.9227\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9600\n",
            "Epoch 00027: val_loss improved from 0.05587 to 0.05370, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.0395 - accuracy: 0.9600 - val_loss: 0.0537 - val_accuracy: 0.9503\n",
            "Epoch 28/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9622\n",
            "Epoch 00028: val_loss did not improve from 0.05370\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.0392 - accuracy: 0.9623 - val_loss: 0.0746 - val_accuracy: 0.9392\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9636\n",
            "Epoch 00029: val_loss did not improve from 0.05370\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.0397 - accuracy: 0.9636 - val_loss: 0.0692 - val_accuracy: 0.9448\n",
            "Epoch 30/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0345 - accuracy: 0.9652\n",
            "Epoch 00030: val_loss did not improve from 0.05370\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.0349 - accuracy: 0.9649 - val_loss: 0.0662 - val_accuracy: 0.9227\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9676\n",
            "Epoch 00031: val_loss did not improve from 0.05370\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.0346 - accuracy: 0.9676 - val_loss: 0.0770 - val_accuracy: 0.9282\n",
            "Epoch 32/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.9617\n",
            "Epoch 00032: val_loss did not improve from 0.05370\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.0373 - accuracy: 0.9618 - val_loss: 0.0699 - val_accuracy: 0.9448\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9595\n",
            "Epoch 00033: val_loss did not improve from 0.05370\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0391 - accuracy: 0.9595 - val_loss: 0.0727 - val_accuracy: 0.9392\n",
            "Epoch 34/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9617\n",
            "Epoch 00034: val_loss did not improve from 0.05370\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0376 - accuracy: 0.9613 - val_loss: 0.0873 - val_accuracy: 0.9116\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9641\n",
            "Epoch 00035: val_loss did not improve from 0.05370\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.0398 - accuracy: 0.9641 - val_loss: 0.0788 - val_accuracy: 0.9392\n",
            "Epoch 36/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9627\n",
            "Epoch 00036: val_loss did not improve from 0.05370\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.0368 - accuracy: 0.9628 - val_loss: 0.1070 - val_accuracy: 0.9061\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9641\n",
            "Epoch 00037: val_loss did not improve from 0.05370\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.0388 - accuracy: 0.9641 - val_loss: 0.0720 - val_accuracy: 0.9282\n",
            "Epoch 38/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0334 - accuracy: 0.9678\n",
            "Epoch 00038: val_loss did not improve from 0.05370\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0331 - accuracy: 0.9679 - val_loss: 0.0596 - val_accuracy: 0.9392\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9656\n",
            "Epoch 00039: val_loss improved from 0.05370 to 0.04636, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.0330 - accuracy: 0.9656 - val_loss: 0.0464 - val_accuracy: 0.9669\n",
            "Epoch 40/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9698\n",
            "Epoch 00040: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0327 - accuracy: 0.9700 - val_loss: 0.0591 - val_accuracy: 0.9337\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9696\n",
            "Epoch 00041: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0295 - accuracy: 0.9696 - val_loss: 0.0703 - val_accuracy: 0.9282\n",
            "Epoch 42/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9739\n",
            "Epoch 00042: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0275 - accuracy: 0.9740 - val_loss: 0.0856 - val_accuracy: 0.9227\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9636\n",
            "Epoch 00043: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0342 - accuracy: 0.9636 - val_loss: 0.0920 - val_accuracy: 0.9116\n",
            "Epoch 44/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.9698\n",
            "Epoch 00044: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0321 - accuracy: 0.9700 - val_loss: 0.0613 - val_accuracy: 0.9503\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9712\n",
            "Epoch 00045: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0319 - accuracy: 0.9712 - val_loss: 0.0671 - val_accuracy: 0.9337\n",
            "Epoch 46/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9688\n",
            "Epoch 00046: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.0333 - accuracy: 0.9684 - val_loss: 0.0749 - val_accuracy: 0.9392\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9757\n",
            "Epoch 00047: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0277 - accuracy: 0.9757 - val_loss: 0.1101 - val_accuracy: 0.9006\n",
            "Epoch 48/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9678\n",
            "Epoch 00048: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.0316 - accuracy: 0.9674 - val_loss: 0.0591 - val_accuracy: 0.9337\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9706\n",
            "Epoch 00049: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0291 - accuracy: 0.9706 - val_loss: 0.0868 - val_accuracy: 0.9282\n",
            "Epoch 50/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9770\n",
            "Epoch 00050: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0248 - accuracy: 0.9771 - val_loss: 0.0775 - val_accuracy: 0.9227\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9722\n",
            "Epoch 00051: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.0274 - accuracy: 0.9722 - val_loss: 0.0758 - val_accuracy: 0.9337\n",
            "Epoch 52/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9760\n",
            "Epoch 00052: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0279 - accuracy: 0.9761 - val_loss: 0.1191 - val_accuracy: 0.9061\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9808\n",
            "Epoch 00053: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0214 - accuracy: 0.9808 - val_loss: 0.0697 - val_accuracy: 0.9392\n",
            "Epoch 54/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9698\n",
            "Epoch 00054: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0288 - accuracy: 0.9700 - val_loss: 0.0692 - val_accuracy: 0.9392\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9782\n",
            "Epoch 00055: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.0238 - accuracy: 0.9782 - val_loss: 0.0795 - val_accuracy: 0.9337\n",
            "Epoch 56/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9729\n",
            "Epoch 00056: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.0244 - accuracy: 0.9730 - val_loss: 0.0797 - val_accuracy: 0.9392\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9706\n",
            "Epoch 00057: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0291 - accuracy: 0.9706 - val_loss: 0.0732 - val_accuracy: 0.9392\n",
            "Epoch 58/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9785\n",
            "Epoch 00058: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0232 - accuracy: 0.9786 - val_loss: 0.0957 - val_accuracy: 0.9227\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9712\n",
            "Epoch 00059: val_loss did not improve from 0.04636\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0287 - accuracy: 0.9712 - val_loss: 0.0804 - val_accuracy: 0.9337\n",
            "Epoch 00059: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ49lSm_e5ZU",
        "colab_type": "code",
        "outputId": "967ea4fe-ab7e-412f-b758-1bb550c4a956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss') \n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'lower left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRDa-TXIKVoS",
        "colab_type": "code",
        "outputId": "9132dfad-3c76-47da-ee76-8f121e9a907e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "validation_loss_vgg16, validation_acc_vgg16 = vgg16_model.evaluate_generator(validation_genrator_VGG16, steps=10)\n",
        "print( 'validation_acc:', validation_acc_vgg16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-112d9c3b83df>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.evaluate, which supports generators.\n",
            "validation_acc: 0.9337016344070435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOgCHUAkKuqk",
        "colab_type": "code",
        "outputId": "738961b3-c36a-47f5-d3c1-331ee3c6853a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_loss_vgg16, test_acc_vgg16 = vgg16_model.evaluate_generator(test_generator_VGG16, steps=30)\n",
        "print('test_acc:', test_acc_vgg16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.8830409646034241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvaeKsM5kvmI",
        "colab_type": "text"
      },
      "source": [
        "###**VGG16 with Dropout Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oRulRvlc7rp",
        "colab_type": "code",
        "outputId": "461b0b74-a9f6-4f07-dadd-0469adc7774f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen_VGG16_1 = ImageDataGenerator(rotation_range=20,\n",
        "                               width_shift_range=0.2,\n",
        "                               height_shift_range=0.2,\n",
        "                               shear_range=0.2,\n",
        "                               zoom_range=0.2,\n",
        "                               horizontal_flip=True,\n",
        "                               rescale=1./255,\n",
        "                               fill_mode='nearest')\n",
        "\n",
        "validation_datagen_VGG16_1 = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen_VGG16_1 = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator_VGG16_1 = train_datagen_VGG16_1.flow_from_directory(Train_dir,\n",
        "                                                    target_size = (140, 90),\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    shuffle=True\n",
        "                                                    )\n",
        "\n",
        "validation_genrator_VGG16_1 = validation_datagen_VGG16_1.flow_from_directory(Valid_dir, \n",
        "                                                   target_size=(140, 90),\n",
        "                                                   batch_size = 181,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=True)\n",
        " \n",
        "test_generator_VGG16_1 = test_datagen_VGG16_1.flow_from_directory(Test_dir, \n",
        "                                                  target_size = (140, 90),\n",
        "                                                  batch_size = 171,\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 788 images belonging to 6 classes.\n",
            "Found 181 images belonging to 6 classes.\n",
            "Found 171 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWoOU3CSkSRh",
        "colab_type": "code",
        "outputId": "d4dd1473-26ef-43bf-b20a-6082807e211e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "K.clear_session()\n",
        "vgg16_model_1 = models.Sequential()\n",
        "vgg16_model_1.add(conv_base_vgg16)\n",
        "vgg16_model_1.add(layers.Flatten())\n",
        "vgg16_model_1.add(layers.Dense(256, activation='relu'))\n",
        "vgg16_model_1.add(layers.Dropout(0.5))\n",
        "vgg16_model_1.add(layers.Dense(6, activation='sigmoid'))\n",
        "\n",
        "vgg16_model_1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 4, 2, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               1048832   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 1542      \n",
            "=================================================================\n",
            "Total params: 15,765,062\n",
            "Trainable params: 1,050,374\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGVYxeVaN-O5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_c = ModelCheckpoint(filepath = 'my_best_model.hdf2', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "callback_d = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWmLNZpuLk60",
        "colab_type": "code",
        "outputId": "fd664f13-8c1c-42eb-e1de-89966b70faa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vgg16_model_1.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_1 = vgg16_model_1.fit_generator(train_generator_VGG16_1, \n",
        "                                    steps_per_epoch=100,\n",
        "                                    epochs=100,\n",
        "                                    callbacks=[callback_c, callback_d],\n",
        "                                    validation_data=validation_genrator_VGG16_1,\n",
        "                                    validation_steps=valid_images.shape[0] / 10\n",
        "                                  )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.5309\n",
            "Epoch 00001: val_loss improved from inf to 0.20135, saving model to my_best_model.hdf2\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.3538 - accuracy: 0.5309 - val_loss: 0.2014 - val_accuracy: 0.8011\n",
            "Epoch 2/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.7255\n",
            "Epoch 00002: val_loss improved from 0.20135 to 0.14273, saving model to my_best_model.hdf2\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2308 - accuracy: 0.7245 - val_loss: 0.1427 - val_accuracy: 0.8508\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2012 - accuracy: 0.7621\n",
            "Epoch 00003: val_loss improved from 0.14273 to 0.13346, saving model to my_best_model.hdf2\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.2012 - accuracy: 0.7621 - val_loss: 0.1335 - val_accuracy: 0.8508\n",
            "Epoch 4/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1669 - accuracy: 0.8195\n",
            "Epoch 00004: val_loss improved from 0.13346 to 0.10361, saving model to my_best_model.hdf2\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.1668 - accuracy: 0.8192 - val_loss: 0.1036 - val_accuracy: 0.9061\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1449 - accuracy: 0.8451\n",
            "Epoch 00005: val_loss improved from 0.10361 to 0.08901, saving model to my_best_model.hdf2\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.1449 - accuracy: 0.8451 - val_loss: 0.0890 - val_accuracy: 0.8950\n",
            "Epoch 6/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1320 - accuracy: 0.8563\n",
            "Epoch 00006: val_loss did not improve from 0.08901\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.1312 - accuracy: 0.8569 - val_loss: 0.0935 - val_accuracy: 0.9006\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.8522\n",
            "Epoch 00007: val_loss improved from 0.08901 to 0.08442, saving model to my_best_model.hdf2\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.1315 - accuracy: 0.8522 - val_loss: 0.0844 - val_accuracy: 0.9227\n",
            "Epoch 8/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1215 - accuracy: 0.8732\n",
            "Epoch 00008: val_loss did not improve from 0.08442\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.1212 - accuracy: 0.8732 - val_loss: 0.0966 - val_accuracy: 0.9006\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.8689\n",
            "Epoch 00009: val_loss did not improve from 0.08442\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.1261 - accuracy: 0.8689 - val_loss: 0.0954 - val_accuracy: 0.9006\n",
            "Epoch 10/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1125 - accuracy: 0.8753\n",
            "Epoch 00010: val_loss improved from 0.08442 to 0.07019, saving model to my_best_model.hdf2\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.1130 - accuracy: 0.8742 - val_loss: 0.0702 - val_accuracy: 0.9337\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.8836\n",
            "Epoch 00011: val_loss improved from 0.07019 to 0.06873, saving model to my_best_model.hdf2\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.1070 - accuracy: 0.8836 - val_loss: 0.0687 - val_accuracy: 0.9448\n",
            "Epoch 12/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.1056 - accuracy: 0.8809\n",
            "Epoch 00012: val_loss improved from 0.06873 to 0.06515, saving model to my_best_model.hdf2\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.1052 - accuracy: 0.8814 - val_loss: 0.0651 - val_accuracy: 0.9392\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.8978\n",
            "Epoch 00013: val_loss did not improve from 0.06515\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0977 - accuracy: 0.8978 - val_loss: 0.0658 - val_accuracy: 0.9558\n",
            "Epoch 14/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0938 - accuracy: 0.9039\n",
            "Epoch 00014: val_loss did not improve from 0.06515\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0934 - accuracy: 0.9043 - val_loss: 0.0748 - val_accuracy: 0.9227\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9059\n",
            "Epoch 00015: val_loss improved from 0.06515 to 0.05573, saving model to my_best_model.hdf2\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.0917 - accuracy: 0.9059 - val_loss: 0.0557 - val_accuracy: 0.9613\n",
            "Epoch 16/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 0.9003\n",
            "Epoch 00016: val_loss did not improve from 0.05573\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.0917 - accuracy: 0.9007 - val_loss: 0.0586 - val_accuracy: 0.9558\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9069\n",
            "Epoch 00017: val_loss did not improve from 0.05573\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0927 - accuracy: 0.9069 - val_loss: 0.0675 - val_accuracy: 0.9337\n",
            "Epoch 18/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0884 - accuracy: 0.9064\n",
            "Epoch 00018: val_loss did not improve from 0.05573\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0885 - accuracy: 0.9068 - val_loss: 0.0625 - val_accuracy: 0.9282\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9114\n",
            "Epoch 00019: val_loss did not improve from 0.05573\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0832 - accuracy: 0.9114 - val_loss: 0.0773 - val_accuracy: 0.8950\n",
            "Epoch 20/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0922 - accuracy: 0.8988\n",
            "Epoch 00020: val_loss did not improve from 0.05573\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0933 - accuracy: 0.8982 - val_loss: 0.0705 - val_accuracy: 0.9227\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9064\n",
            "Epoch 00021: val_loss improved from 0.05573 to 0.05036, saving model to my_best_model.hdf2\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.0854 - accuracy: 0.9064 - val_loss: 0.0504 - val_accuracy: 0.9337\n",
            "Epoch 22/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0837 - accuracy: 0.9126\n",
            "Epoch 00022: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0836 - accuracy: 0.9124 - val_loss: 0.0663 - val_accuracy: 0.9392\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9200\n",
            "Epoch 00023: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0788 - accuracy: 0.9200 - val_loss: 0.0592 - val_accuracy: 0.9282\n",
            "Epoch 24/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9131\n",
            "Epoch 00024: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.0827 - accuracy: 0.9134 - val_loss: 0.0526 - val_accuracy: 0.9448\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9119\n",
            "Epoch 00025: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0802 - accuracy: 0.9119 - val_loss: 0.0608 - val_accuracy: 0.9392\n",
            "Epoch 26/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9320\n",
            "Epoch 00026: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0708 - accuracy: 0.9318 - val_loss: 0.0536 - val_accuracy: 0.9558\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9221\n",
            "Epoch 00027: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0736 - accuracy: 0.9221 - val_loss: 0.0585 - val_accuracy: 0.9392\n",
            "Epoch 28/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0726 - accuracy: 0.9279\n",
            "Epoch 00028: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0727 - accuracy: 0.9282 - val_loss: 0.0639 - val_accuracy: 0.9227\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9190\n",
            "Epoch 00029: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0741 - accuracy: 0.9190 - val_loss: 0.0652 - val_accuracy: 0.9282\n",
            "Epoch 30/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 0.9269\n",
            "Epoch 00030: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.0742 - accuracy: 0.9272 - val_loss: 0.0528 - val_accuracy: 0.9503\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9281\n",
            "Epoch 00031: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0684 - accuracy: 0.9281 - val_loss: 0.0616 - val_accuracy: 0.9503\n",
            "Epoch 32/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0735 - accuracy: 0.9254\n",
            "Epoch 00032: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0729 - accuracy: 0.9257 - val_loss: 0.0604 - val_accuracy: 0.9558\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9165\n",
            "Epoch 00033: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0764 - accuracy: 0.9165 - val_loss: 0.0929 - val_accuracy: 0.9116\n",
            "Epoch 34/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.9208\n",
            "Epoch 00034: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0737 - accuracy: 0.9211 - val_loss: 0.0591 - val_accuracy: 0.9282\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9352\n",
            "Epoch 00035: val_loss did not improve from 0.05036\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0663 - accuracy: 0.9352 - val_loss: 0.0599 - val_accuracy: 0.9392\n",
            "Epoch 36/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9305\n",
            "Epoch 00036: val_loss improved from 0.05036 to 0.04945, saving model to my_best_model.hdf2\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0678 - accuracy: 0.9302 - val_loss: 0.0494 - val_accuracy: 0.9558\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9256\n",
            "Epoch 00037: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0719 - accuracy: 0.9256 - val_loss: 0.0663 - val_accuracy: 0.9337\n",
            "Epoch 38/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9264\n",
            "Epoch 00038: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0718 - accuracy: 0.9262 - val_loss: 0.0654 - val_accuracy: 0.9337\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9246\n",
            "Epoch 00039: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0672 - accuracy: 0.9246 - val_loss: 0.0525 - val_accuracy: 0.9558\n",
            "Epoch 40/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 0.9315\n",
            "Epoch 00040: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.0653 - accuracy: 0.9313 - val_loss: 0.0694 - val_accuracy: 0.9171\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9322\n",
            "Epoch 00041: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.0670 - accuracy: 0.9322 - val_loss: 0.0718 - val_accuracy: 0.9227\n",
            "Epoch 42/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 0.9294\n",
            "Epoch 00042: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.0658 - accuracy: 0.9297 - val_loss: 0.0890 - val_accuracy: 0.9227\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9322\n",
            "Epoch 00043: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0655 - accuracy: 0.9322 - val_loss: 0.0577 - val_accuracy: 0.9392\n",
            "Epoch 44/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9223\n",
            "Epoch 00044: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.0676 - accuracy: 0.9221 - val_loss: 0.0671 - val_accuracy: 0.9392\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9393\n",
            "Epoch 00045: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.0605 - accuracy: 0.9393 - val_loss: 0.0683 - val_accuracy: 0.9282\n",
            "Epoch 46/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0673 - accuracy: 0.9315\n",
            "Epoch 00046: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0676 - accuracy: 0.9313 - val_loss: 0.0689 - val_accuracy: 0.9337\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9367\n",
            "Epoch 00047: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.0642 - accuracy: 0.9367 - val_loss: 0.0550 - val_accuracy: 0.9282\n",
            "Epoch 48/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0622 - accuracy: 0.9315\n",
            "Epoch 00048: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.0620 - accuracy: 0.9313 - val_loss: 0.0602 - val_accuracy: 0.9337\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9291\n",
            "Epoch 00049: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.0656 - accuracy: 0.9291 - val_loss: 0.0603 - val_accuracy: 0.9337\n",
            "Epoch 50/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0551 - accuracy: 0.9422\n",
            "Epoch 00050: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0552 - accuracy: 0.9420 - val_loss: 0.0601 - val_accuracy: 0.9392\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9398\n",
            "Epoch 00051: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0587 - accuracy: 0.9398 - val_loss: 0.0681 - val_accuracy: 0.9337\n",
            "Epoch 52/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0670 - accuracy: 0.9305\n",
            "Epoch 00052: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0670 - accuracy: 0.9308 - val_loss: 0.0634 - val_accuracy: 0.9392\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9383\n",
            "Epoch 00053: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0575 - accuracy: 0.9383 - val_loss: 0.0616 - val_accuracy: 0.9503\n",
            "Epoch 54/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9397\n",
            "Epoch 00054: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.0582 - accuracy: 0.9394 - val_loss: 0.0725 - val_accuracy: 0.9282\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9393\n",
            "Epoch 00055: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0584 - accuracy: 0.9393 - val_loss: 0.0763 - val_accuracy: 0.9227\n",
            "Epoch 56/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0611 - accuracy: 0.9356\n",
            "Epoch 00056: val_loss did not improve from 0.04945\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.0615 - accuracy: 0.9353 - val_loss: 0.0599 - val_accuracy: 0.9392\n",
            "Epoch 00056: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHnG1ftpk-YV",
        "colab_type": "code",
        "outputId": "85f2cb32-964c-4c2c-8b2d-be46f5fbea0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history_1.history['accuracy'])\n",
        "plt.plot(history_1.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_1.history['loss'])\n",
        "plt.plot(history_1.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'lower left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPVB1p0LUThP",
        "colab_type": "code",
        "outputId": "b298a89d-3579-4234-e328-0b1fe23c629f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "validation_loss_vgg16_1, validation_acc_vgg16_1 = vgg16_model_1.evaluate_generator(validation_genrator_VGG16_1, steps=10)\n",
        "print( 'validation_acc:', validation_acc_vgg16_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation_acc: 0.939226508140564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGDPg6hZUZny",
        "colab_type": "code",
        "outputId": "1066e784-c640-4ceb-a26c-81e3e7ec5ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_loss_vgg16_1, test_acc_vgg16_1 = vgg16_model_1.evaluate_generator(test_generator_VGG16_1, steps=30)\n",
        "print('test_acc:', test_acc_vgg16_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.8538011908531189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPKkqk_VPCoI",
        "colab_type": "text"
      },
      "source": [
        "## **ResNet50**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHgIw7_BcnN4",
        "colab_type": "code",
        "outputId": "091cd111-c26d-4710-a98c-fdb6e24629a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen_ResNet50 = ImageDataGenerator(rotation_range=20,\n",
        "                               width_shift_range=0.2,\n",
        "                               height_shift_range=0.2,\n",
        "                               shear_range=0.2,\n",
        "                               zoom_range=0.2,\n",
        "                               horizontal_flip=True,\n",
        "                               rescale=1./255,\n",
        "                               fill_mode='nearest')\n",
        "\n",
        "validation_datagen_ResNet50 = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen_ResNet50 = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator_ResNet50 = train_datagen_ResNet50.flow_from_directory(Train_dir,\n",
        "                                                    target_size = (140, 90),\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    shuffle=True\n",
        "                                                    )\n",
        "\n",
        "validation_genrator_ResNet50 = validation_datagen_ResNet50.flow_from_directory(Valid_dir, \n",
        "                                                   target_size=(140, 90),\n",
        "                                                   batch_size = 181,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=True)\n",
        " \n",
        "test_generator_ResNet50 = test_datagen_ResNet50.flow_from_directory(Test_dir, \n",
        "                                                  target_size = (140, 90),\n",
        "                                                  batch_size = 171 ,\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 788 images belonging to 6 classes.\n",
            "Found 181 images belonging to 6 classes.\n",
            "Found 171 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1h76s1jlN7r",
        "colab_type": "code",
        "outputId": "5722cda6-76ef-4536-dccf-b76609eb2f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(140, 90, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myAL6otWdSjt",
        "colab_type": "code",
        "outputId": "3f549ed3-4d40-493d-a22e-1b105de920a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 140, 90, 3)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 146, 96, 3)   0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 70, 45, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 70, 45, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 70, 45, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 72, 47, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 35, 23, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 35, 23, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 35, 23, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 35, 23, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 35, 23, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 35, 23, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 35, 23, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 35, 23, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 35, 23, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 35, 23, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 35, 23, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 35, 23, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 35, 23, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 35, 23, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 35, 23, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 35, 23, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 35, 23, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 35, 23, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 35, 23, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 35, 23, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 35, 23, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 35, 23, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 35, 23, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 35, 23, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 35, 23, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 35, 23, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 35, 23, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 35, 23, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 35, 23, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 35, 23, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 35, 23, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 35, 23, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 35, 23, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 18, 12, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 18, 12, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 18, 12, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 18, 12, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 18, 12, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 18, 12, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 18, 12, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 18, 12, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 18, 12, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 18, 12, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 18, 12, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 18, 12, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 18, 12, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 18, 12, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 18, 12, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 18, 12, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 18, 12, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 18, 12, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 18, 12, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 18, 12, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 18, 12, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 18, 12, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 18, 12, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 18, 12, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 18, 12, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 18, 12, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 18, 12, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 18, 12, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 18, 12, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 18, 12, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 18, 12, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 18, 12, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 18, 12, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 18, 12, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 18, 12, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 18, 12, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 18, 12, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 18, 12, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 18, 12, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 18, 12, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 18, 12, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 18, 12, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 9, 6, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 9, 6, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 9, 6, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 9, 6, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 9, 6, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 9, 6, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 9, 6, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 9, 6, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 9, 6, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 9, 6, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 9, 6, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 9, 6, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 9, 6, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 9, 6, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 9, 6, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 9, 6, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 9, 6, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 9, 6, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 9, 6, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 9, 6, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 9, 6, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 9, 6, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 9, 6, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 9, 6, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 9, 6, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 9, 6, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 9, 6, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 9, 6, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 9, 6, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 9, 6, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 9, 6, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 9, 6, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 9, 6, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 9, 6, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 9, 6, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 9, 6, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 9, 6, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 9, 6, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 9, 6, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 9, 6, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 9, 6, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 9, 6, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 9, 6, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 9, 6, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 9, 6, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 9, 6, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 9, 6, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 9, 6, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 9, 6, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 9, 6, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 9, 6, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 9, 6, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 9, 6, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 9, 6, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 9, 6, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 9, 6, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 9, 6, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 9, 6, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 9, 6, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 9, 6, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 9, 6, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 9, 6, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 5, 3, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 5, 3, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 5, 3, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 5, 3, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 5, 3, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 5, 3, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 5, 3, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 5, 3, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 5, 3, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 5, 3, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 5, 3, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 5, 3, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 5, 3, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 5, 3, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 5, 3, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 5, 3, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 5, 3, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 5, 3, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 5, 3, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 5, 3, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 5, 3, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 5, 3, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 5, 3, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 5, 3, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 5, 3, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 5, 3, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 5, 3, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 5, 3, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 5, 3, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 5, 3, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 5, 3, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 5, 3, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9sXx0fciIl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in resnet_model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXOR6vtEOo4h",
        "colab_type": "code",
        "outputId": "11da0c9e-f89a-4219-805c-e1628b814f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "K.clear_session()\n",
        "resnet50_model = models.Sequential()\n",
        "resnet50_model.add(resnet_model)\n",
        "resnet50_model.add(layers.Flatten())\n",
        "resnet50_model.add(layers.Dense(256, activation='relu'))\n",
        "resnet50_model.add(layers.Dense(6, activation='sigmoid'))\n",
        "\n",
        "resnet50_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 5, 3, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30720)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               7864576   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 1542      \n",
            "=================================================================\n",
            "Total params: 31,453,830\n",
            "Trainable params: 7,866,118\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt5uMh_-dX8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_e = ModelCheckpoint(filepath = 'my_best_model.hdf3', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "callback_f = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_4RS6V-ddFA",
        "colab_type": "code",
        "outputId": "697c397f-9670-4b36-9e62-6ba98abc7f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet50_model.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_resnet50 = resnet50_model.fit_generator(train_generator_ResNet50, \n",
        "                                    steps_per_epoch=100,\n",
        "                                    epochs=100,\n",
        "                                    callbacks=[callback_e, callback_f],\n",
        "                                    validation_data=validation_genrator_ResNet50,\n",
        "                                    validation_steps=valid_images.shape[0] / 10\n",
        "                                  )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.2667\n",
            "Epoch 00001: val_loss improved from inf to 0.44696, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.4601 - accuracy: 0.2667 - val_loss: 0.4470 - val_accuracy: 0.2762\n",
            "Epoch 2/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4265 - accuracy: 0.3190\n",
            "Epoch 00002: val_loss improved from 0.44696 to 0.39626, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.4260 - accuracy: 0.3198 - val_loss: 0.3963 - val_accuracy: 0.3315\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3878 - accuracy: 0.4130\n",
            "Epoch 00003: val_loss improved from 0.39626 to 0.37783, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.3878 - accuracy: 0.4130 - val_loss: 0.3778 - val_accuracy: 0.4309\n",
            "Epoch 4/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3757 - accuracy: 0.4417\n",
            "Epoch 00004: val_loss improved from 0.37783 to 0.34084, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3756 - accuracy: 0.4409 - val_loss: 0.3408 - val_accuracy: 0.4917\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3581 - accuracy: 0.4742\n",
            "Epoch 00005: val_loss did not improve from 0.34084\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.3581 - accuracy: 0.4742 - val_loss: 0.3413 - val_accuracy: 0.5028\n",
            "Epoch 6/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3558 - accuracy: 0.4857\n",
            "Epoch 00006: val_loss improved from 0.34084 to 0.32731, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.3556 - accuracy: 0.4852 - val_loss: 0.3273 - val_accuracy: 0.5249\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3416 - accuracy: 0.5066\n",
            "Epoch 00007: val_loss did not improve from 0.32731\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.3416 - accuracy: 0.5066 - val_loss: 0.3340 - val_accuracy: 0.4586\n",
            "Epoch 8/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3378 - accuracy: 0.5020\n",
            "Epoch 00008: val_loss improved from 0.32731 to 0.32408, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 14s 135ms/step - loss: 0.3370 - accuracy: 0.5036 - val_loss: 0.3241 - val_accuracy: 0.5028\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.5152\n",
            "Epoch 00009: val_loss improved from 0.32408 to 0.29899, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.3326 - accuracy: 0.5152 - val_loss: 0.2990 - val_accuracy: 0.5359\n",
            "Epoch 10/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3227 - accuracy: 0.5562\n",
            "Epoch 00010: val_loss did not improve from 0.29899\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.3210 - accuracy: 0.5575 - val_loss: 0.3120 - val_accuracy: 0.5304\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.5374\n",
            "Epoch 00011: val_loss did not improve from 0.29899\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.3221 - accuracy: 0.5374 - val_loss: 0.3035 - val_accuracy: 0.5359\n",
            "Epoch 12/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3203 - accuracy: 0.5435\n",
            "Epoch 00012: val_loss did not improve from 0.29899\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3192 - accuracy: 0.5443 - val_loss: 0.3131 - val_accuracy: 0.5304\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3101 - accuracy: 0.5496\n",
            "Epoch 00013: val_loss did not improve from 0.29899\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.3101 - accuracy: 0.5496 - val_loss: 0.3012 - val_accuracy: 0.5856\n",
            "Epoch 14/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3052 - accuracy: 0.5711\n",
            "Epoch 00014: val_loss did not improve from 0.29899\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.3048 - accuracy: 0.5718 - val_loss: 0.3292 - val_accuracy: 0.4862\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3020 - accuracy: 0.5825\n",
            "Epoch 00015: val_loss improved from 0.29899 to 0.28464, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.3020 - accuracy: 0.5825 - val_loss: 0.2846 - val_accuracy: 0.5967\n",
            "Epoch 16/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3023 - accuracy: 0.5823\n",
            "Epoch 00016: val_loss did not improve from 0.28464\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.3021 - accuracy: 0.5830 - val_loss: 0.2858 - val_accuracy: 0.5691\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3025 - accuracy: 0.5739\n",
            "Epoch 00017: val_loss did not improve from 0.28464\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.3025 - accuracy: 0.5739 - val_loss: 0.2888 - val_accuracy: 0.5414\n",
            "Epoch 18/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2929 - accuracy: 0.5833\n",
            "Epoch 00018: val_loss did not improve from 0.28464\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2930 - accuracy: 0.5830 - val_loss: 0.2935 - val_accuracy: 0.5414\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2924 - accuracy: 0.6007\n",
            "Epoch 00019: val_loss improved from 0.28464 to 0.27625, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2924 - accuracy: 0.6007 - val_loss: 0.2763 - val_accuracy: 0.5912\n",
            "Epoch 20/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2950 - accuracy: 0.5890\n",
            "Epoch 00020: val_loss improved from 0.27625 to 0.25867, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.2965 - accuracy: 0.5881 - val_loss: 0.2587 - val_accuracy: 0.6298\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.6123\n",
            "Epoch 00021: val_loss did not improve from 0.25867\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.2857 - accuracy: 0.6123 - val_loss: 0.2632 - val_accuracy: 0.6630\n",
            "Epoch 22/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2914 - accuracy: 0.5925\n",
            "Epoch 00022: val_loss did not improve from 0.25867\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.2907 - accuracy: 0.5932 - val_loss: 0.2644 - val_accuracy: 0.5967\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.6169\n",
            "Epoch 00023: val_loss did not improve from 0.25867\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2832 - accuracy: 0.6169 - val_loss: 0.2903 - val_accuracy: 0.6243\n",
            "Epoch 24/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2899 - accuracy: 0.5946\n",
            "Epoch 00024: val_loss did not improve from 0.25867\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2900 - accuracy: 0.5937 - val_loss: 0.2928 - val_accuracy: 0.5746\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.6002\n",
            "Epoch 00025: val_loss did not improve from 0.25867\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2877 - accuracy: 0.6002 - val_loss: 0.2797 - val_accuracy: 0.5967\n",
            "Epoch 26/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2740 - accuracy: 0.6176\n",
            "Epoch 00026: val_loss did not improve from 0.25867\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2728 - accuracy: 0.6181 - val_loss: 0.2759 - val_accuracy: 0.6077\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2822 - accuracy: 0.6032\n",
            "Epoch 00027: val_loss improved from 0.25867 to 0.25387, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2822 - accuracy: 0.6032 - val_loss: 0.2539 - val_accuracy: 0.6575\n",
            "Epoch 28/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2868 - accuracy: 0.6033\n",
            "Epoch 00028: val_loss did not improve from 0.25387\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.2875 - accuracy: 0.6029 - val_loss: 0.3089 - val_accuracy: 0.5249\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.5815\n",
            "Epoch 00029: val_loss did not improve from 0.25387\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.2870 - accuracy: 0.5815 - val_loss: 0.2769 - val_accuracy: 0.5580\n",
            "Epoch 30/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2717 - accuracy: 0.6396\n",
            "Epoch 00030: val_loss did not improve from 0.25387\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2722 - accuracy: 0.6390 - val_loss: 0.2541 - val_accuracy: 0.6022\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.6032\n",
            "Epoch 00031: val_loss improved from 0.25387 to 0.24973, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.2844 - accuracy: 0.6032 - val_loss: 0.2497 - val_accuracy: 0.6354\n",
            "Epoch 32/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2838 - accuracy: 0.6048\n",
            "Epoch 00032: val_loss did not improve from 0.24973\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.2840 - accuracy: 0.6044 - val_loss: 0.2798 - val_accuracy: 0.6077\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.6210\n",
            "Epoch 00033: val_loss did not improve from 0.24973\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.2738 - accuracy: 0.6210 - val_loss: 0.2882 - val_accuracy: 0.5525\n",
            "Epoch 34/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2768 - accuracy: 0.6227\n",
            "Epoch 00034: val_loss did not improve from 0.24973\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.2767 - accuracy: 0.6232 - val_loss: 0.2619 - val_accuracy: 0.6685\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.6037\n",
            "Epoch 00035: val_loss did not improve from 0.24973\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2821 - accuracy: 0.6037 - val_loss: 0.2568 - val_accuracy: 0.6188\n",
            "Epoch 36/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2685 - accuracy: 0.6222\n",
            "Epoch 00036: val_loss did not improve from 0.24973\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2694 - accuracy: 0.6217 - val_loss: 0.2542 - val_accuracy: 0.5912\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.6336\n",
            "Epoch 00037: val_loss did not improve from 0.24973\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2641 - accuracy: 0.6336 - val_loss: 0.2533 - val_accuracy: 0.5912\n",
            "Epoch 38/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2637 - accuracy: 0.6416\n",
            "Epoch 00038: val_loss did not improve from 0.24973\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2633 - accuracy: 0.6415 - val_loss: 0.2647 - val_accuracy: 0.5912\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.6260\n",
            "Epoch 00039: val_loss improved from 0.24973 to 0.23878, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2665 - accuracy: 0.6260 - val_loss: 0.2388 - val_accuracy: 0.6519\n",
            "Epoch 40/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2699 - accuracy: 0.6360\n",
            "Epoch 00040: val_loss did not improve from 0.23878\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2695 - accuracy: 0.6359 - val_loss: 0.3063 - val_accuracy: 0.5967\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.6326\n",
            "Epoch 00041: val_loss did not improve from 0.23878\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.2666 - accuracy: 0.6326 - val_loss: 0.2656 - val_accuracy: 0.6298\n",
            "Epoch 42/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2621 - accuracy: 0.6339\n",
            "Epoch 00042: val_loss improved from 0.23878 to 0.23229, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2626 - accuracy: 0.6339 - val_loss: 0.2323 - val_accuracy: 0.6961\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2656 - accuracy: 0.6427\n",
            "Epoch 00043: val_loss did not improve from 0.23229\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.2656 - accuracy: 0.6427 - val_loss: 0.2373 - val_accuracy: 0.6906\n",
            "Epoch 44/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2642 - accuracy: 0.6309\n",
            "Epoch 00044: val_loss did not improve from 0.23229\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2644 - accuracy: 0.6303 - val_loss: 0.2360 - val_accuracy: 0.6961\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2716 - accuracy: 0.6154\n",
            "Epoch 00045: val_loss did not improve from 0.23229\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2716 - accuracy: 0.6154 - val_loss: 0.2376 - val_accuracy: 0.6409\n",
            "Epoch 46/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2725 - accuracy: 0.6176\n",
            "Epoch 00046: val_loss did not improve from 0.23229\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2722 - accuracy: 0.6176 - val_loss: 0.2701 - val_accuracy: 0.6077\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2574 - accuracy: 0.6437\n",
            "Epoch 00047: val_loss did not improve from 0.23229\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2574 - accuracy: 0.6437 - val_loss: 0.2430 - val_accuracy: 0.6906\n",
            "Epoch 48/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.6324\n",
            "Epoch 00048: val_loss did not improve from 0.23229\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2670 - accuracy: 0.6329 - val_loss: 0.2611 - val_accuracy: 0.6133\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2656 - accuracy: 0.6366\n",
            "Epoch 00049: val_loss did not improve from 0.23229\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.2656 - accuracy: 0.6366 - val_loss: 0.2363 - val_accuracy: 0.6740\n",
            "Epoch 50/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2647 - accuracy: 0.6421\n",
            "Epoch 00050: val_loss did not improve from 0.23229\n",
            "100/100 [==============================] - 12s 120ms/step - loss: 0.2645 - accuracy: 0.6426 - val_loss: 0.2419 - val_accuracy: 0.6740\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2631 - accuracy: 0.6377\n",
            "Epoch 00051: val_loss did not improve from 0.23229\n",
            "100/100 [==============================] - 12s 120ms/step - loss: 0.2631 - accuracy: 0.6377 - val_loss: 0.2575 - val_accuracy: 0.6575\n",
            "Epoch 52/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2640 - accuracy: 0.6406\n",
            "Epoch 00052: val_loss improved from 0.23229 to 0.23225, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.2637 - accuracy: 0.6410 - val_loss: 0.2322 - val_accuracy: 0.6906\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2585 - accuracy: 0.6452\n",
            "Epoch 00053: val_loss did not improve from 0.23225\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.2585 - accuracy: 0.6452 - val_loss: 0.2515 - val_accuracy: 0.6519\n",
            "Epoch 54/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2605 - accuracy: 0.6493\n",
            "Epoch 00054: val_loss did not improve from 0.23225\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2607 - accuracy: 0.6487 - val_loss: 0.2557 - val_accuracy: 0.6575\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2513 - accuracy: 0.6564\n",
            "Epoch 00055: val_loss did not improve from 0.23225\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2513 - accuracy: 0.6564 - val_loss: 0.2337 - val_accuracy: 0.6906\n",
            "Epoch 56/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2515 - accuracy: 0.6585\n",
            "Epoch 00056: val_loss did not improve from 0.23225\n",
            "100/100 [==============================] - 12s 120ms/step - loss: 0.2504 - accuracy: 0.6594 - val_loss: 0.2553 - val_accuracy: 0.5912\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2624 - accuracy: 0.6382\n",
            "Epoch 00057: val_loss did not improve from 0.23225\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.2624 - accuracy: 0.6382 - val_loss: 0.2371 - val_accuracy: 0.6354\n",
            "Epoch 58/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2477 - accuracy: 0.6702\n",
            "Epoch 00058: val_loss did not improve from 0.23225\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.2487 - accuracy: 0.6696 - val_loss: 0.2367 - val_accuracy: 0.6575\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.6599\n",
            "Epoch 00059: val_loss did not improve from 0.23225\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2478 - accuracy: 0.6599 - val_loss: 0.2608 - val_accuracy: 0.6133\n",
            "Epoch 60/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2491 - accuracy: 0.6718\n",
            "Epoch 00060: val_loss improved from 0.23225 to 0.23206, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.2498 - accuracy: 0.6716 - val_loss: 0.2321 - val_accuracy: 0.7017\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2556 - accuracy: 0.6478\n",
            "Epoch 00061: val_loss did not improve from 0.23206\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2556 - accuracy: 0.6478 - val_loss: 0.2676 - val_accuracy: 0.6354\n",
            "Epoch 62/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2472 - accuracy: 0.6641\n",
            "Epoch 00062: val_loss improved from 0.23206 to 0.22468, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.2468 - accuracy: 0.6645 - val_loss: 0.2247 - val_accuracy: 0.6685\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2497 - accuracy: 0.6584\n",
            "Epoch 00063: val_loss improved from 0.22468 to 0.22196, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2497 - accuracy: 0.6584 - val_loss: 0.2220 - val_accuracy: 0.7127\n",
            "Epoch 64/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2533 - accuracy: 0.6713\n",
            "Epoch 00064: val_loss did not improve from 0.22196\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.2539 - accuracy: 0.6701 - val_loss: 0.2327 - val_accuracy: 0.6630\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2646 - accuracy: 0.6346\n",
            "Epoch 00065: val_loss did not improve from 0.22196\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2646 - accuracy: 0.6346 - val_loss: 0.2253 - val_accuracy: 0.7127\n",
            "Epoch 66/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2589 - accuracy: 0.6544\n",
            "Epoch 00066: val_loss did not improve from 0.22196\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.2588 - accuracy: 0.6548 - val_loss: 0.2286 - val_accuracy: 0.6740\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2466 - accuracy: 0.6685\n",
            "Epoch 00067: val_loss did not improve from 0.22196\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2466 - accuracy: 0.6685 - val_loss: 0.2368 - val_accuracy: 0.6575\n",
            "Epoch 68/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2521 - accuracy: 0.6534\n",
            "Epoch 00068: val_loss improved from 0.22196 to 0.22154, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.2521 - accuracy: 0.6533 - val_loss: 0.2215 - val_accuracy: 0.6740\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.6549\n",
            "Epoch 00069: val_loss did not improve from 0.22154\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2493 - accuracy: 0.6549 - val_loss: 0.2319 - val_accuracy: 0.6685\n",
            "Epoch 70/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2350 - accuracy: 0.6779\n",
            "Epoch 00070: val_loss did not improve from 0.22154\n",
            "100/100 [==============================] - 12s 120ms/step - loss: 0.2359 - accuracy: 0.6767 - val_loss: 0.2477 - val_accuracy: 0.6575\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.6832\n",
            "Epoch 00071: val_loss improved from 0.22154 to 0.21389, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.2380 - accuracy: 0.6832 - val_loss: 0.2139 - val_accuracy: 0.6519\n",
            "Epoch 72/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2461 - accuracy: 0.6702\n",
            "Epoch 00072: val_loss did not improve from 0.21389\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.2459 - accuracy: 0.6706 - val_loss: 0.2164 - val_accuracy: 0.6796\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.6802\n",
            "Epoch 00073: val_loss did not improve from 0.21389\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2368 - accuracy: 0.6802 - val_loss: 0.2296 - val_accuracy: 0.6519\n",
            "Epoch 74/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2364 - accuracy: 0.6733\n",
            "Epoch 00074: val_loss did not improve from 0.21389\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2384 - accuracy: 0.6721 - val_loss: 0.2543 - val_accuracy: 0.6630\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.6695\n",
            "Epoch 00075: val_loss did not improve from 0.21389\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.2449 - accuracy: 0.6695 - val_loss: 0.2342 - val_accuracy: 0.6409\n",
            "Epoch 76/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2384 - accuracy: 0.6825\n",
            "Epoch 00076: val_loss did not improve from 0.21389\n",
            "100/100 [==============================] - 12s 120ms/step - loss: 0.2381 - accuracy: 0.6828 - val_loss: 0.2148 - val_accuracy: 0.6961\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.6802\n",
            "Epoch 00077: val_loss did not improve from 0.21389\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.2369 - accuracy: 0.6802 - val_loss: 0.2162 - val_accuracy: 0.7238\n",
            "Epoch 78/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2468 - accuracy: 0.6610\n",
            "Epoch 00078: val_loss did not improve from 0.21389\n",
            "100/100 [==============================] - 12s 119ms/step - loss: 0.2461 - accuracy: 0.6619 - val_loss: 0.2382 - val_accuracy: 0.6961\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.6670\n",
            "Epoch 00079: val_loss did not improve from 0.21389\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.2471 - accuracy: 0.6670 - val_loss: 0.2169 - val_accuracy: 0.6519\n",
            "Epoch 80/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2463 - accuracy: 0.6682\n",
            "Epoch 00080: val_loss did not improve from 0.21389\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2459 - accuracy: 0.6685 - val_loss: 0.2180 - val_accuracy: 0.6796\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.6867\n",
            "Epoch 00081: val_loss did not improve from 0.21389\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2337 - accuracy: 0.6867 - val_loss: 0.2233 - val_accuracy: 0.6575\n",
            "Epoch 82/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2414 - accuracy: 0.6631\n",
            "Epoch 00082: val_loss did not improve from 0.21389\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2408 - accuracy: 0.6640 - val_loss: 0.2216 - val_accuracy: 0.6796\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2481 - accuracy: 0.6705\n",
            "Epoch 00083: val_loss improved from 0.21389 to 0.20965, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.2481 - accuracy: 0.6705 - val_loss: 0.2097 - val_accuracy: 0.7017\n",
            "Epoch 84/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2504 - accuracy: 0.6677\n",
            "Epoch 00084: val_loss did not improve from 0.20965\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.2495 - accuracy: 0.6675 - val_loss: 0.2288 - val_accuracy: 0.6685\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2408 - accuracy: 0.6791\n",
            "Epoch 00085: val_loss did not improve from 0.20965\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2408 - accuracy: 0.6791 - val_loss: 0.2100 - val_accuracy: 0.6961\n",
            "Epoch 86/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2376 - accuracy: 0.6810\n",
            "Epoch 00086: val_loss improved from 0.20965 to 0.20601, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 14s 136ms/step - loss: 0.2378 - accuracy: 0.6802 - val_loss: 0.2060 - val_accuracy: 0.6906\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.6827\n",
            "Epoch 00087: val_loss did not improve from 0.20601\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2348 - accuracy: 0.6827 - val_loss: 0.2142 - val_accuracy: 0.7293\n",
            "Epoch 88/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2370 - accuracy: 0.6743\n",
            "Epoch 00088: val_loss did not improve from 0.20601\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2369 - accuracy: 0.6752 - val_loss: 0.2224 - val_accuracy: 0.6740\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2397 - accuracy: 0.6837\n",
            "Epoch 00089: val_loss did not improve from 0.20601\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.2397 - accuracy: 0.6837 - val_loss: 0.2207 - val_accuracy: 0.6906\n",
            "Epoch 90/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2383 - accuracy: 0.6876\n",
            "Epoch 00090: val_loss did not improve from 0.20601\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2379 - accuracy: 0.6879 - val_loss: 0.2290 - val_accuracy: 0.6961\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.6857\n",
            "Epoch 00091: val_loss did not improve from 0.20601\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.2344 - accuracy: 0.6857 - val_loss: 0.2278 - val_accuracy: 0.6575\n",
            "Epoch 92/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2359 - accuracy: 0.6733\n",
            "Epoch 00092: val_loss did not improve from 0.20601\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2345 - accuracy: 0.6746 - val_loss: 0.2086 - val_accuracy: 0.6906\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.6969\n",
            "Epoch 00093: val_loss did not improve from 0.20601\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2323 - accuracy: 0.6969 - val_loss: 0.2275 - val_accuracy: 0.6961\n",
            "Epoch 94/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2316 - accuracy: 0.6968\n",
            "Epoch 00094: val_loss did not improve from 0.20601\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2323 - accuracy: 0.6955 - val_loss: 0.2169 - val_accuracy: 0.7017\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.6872\n",
            "Epoch 00095: val_loss improved from 0.20601 to 0.20323, saving model to my_best_model.hdf3\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.2323 - accuracy: 0.6872 - val_loss: 0.2032 - val_accuracy: 0.7348\n",
            "Epoch 96/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2434 - accuracy: 0.6815\n",
            "Epoch 00096: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2431 - accuracy: 0.6818 - val_loss: 0.2237 - val_accuracy: 0.6740\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.6807\n",
            "Epoch 00097: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2344 - accuracy: 0.6807 - val_loss: 0.2257 - val_accuracy: 0.7127\n",
            "Epoch 98/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2308 - accuracy: 0.6897\n",
            "Epoch 00098: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2317 - accuracy: 0.6889 - val_loss: 0.2087 - val_accuracy: 0.6740\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.6483\n",
            "Epoch 00099: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.2525 - accuracy: 0.6483 - val_loss: 0.2116 - val_accuracy: 0.6851\n",
            "Epoch 100/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2428 - accuracy: 0.6748\n",
            "Epoch 00100: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.2430 - accuracy: 0.6746 - val_loss: 0.2606 - val_accuracy: 0.6851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPoyF9pLdtfu",
        "colab_type": "code",
        "outputId": "a86cdbb2-3018-46ad-914c-503790d2b173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history_resnet50.history['accuracy'])\n",
        "plt.plot(history_resnet50.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_resnet50.history['loss'])\n",
        "plt.plot(history_resnet50.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'lower left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVSP2y5xwfcX",
        "colab_type": "code",
        "outputId": "539c8eb3-ddfc-4838-a956-5c5034fcbed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "validation_loss_Res, validation_acc_Res = resnet50_model.evaluate_generator(validation_genrator_ResNet50, steps=10)\n",
        "print( 'validation_acc:', validation_acc_Res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation_acc: 0.6850828528404236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXfEKP4yxEwa",
        "colab_type": "code",
        "outputId": "b409a935-ed3c-41bc-8b48-e7b3a2b3d5ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_loss_Res, test_acc_Res = resnet50_model.evaluate_generator(test_generator_ResNet50, steps=30)\n",
        "print('test_acc:', test_acc_Res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.6783625483512878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yer8Ol1Fxwd-",
        "colab_type": "code",
        "outputId": "1a1c6820-6366-469f-a8f9-b12460ed6bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen_ResNet50_1= ImageDataGenerator(rotation_range=20,\n",
        "                               width_shift_range=0.2,\n",
        "                               height_shift_range=0.2,\n",
        "                               shear_range=0.2,\n",
        "                               zoom_range=0.2,\n",
        "                               horizontal_flip=True,\n",
        "                               rescale=1./255,\n",
        "                               fill_mode='nearest')\n",
        "\n",
        "validation_datagen_ResNet50_1 = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen_ResNet50_1 = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator_ResNet50_1 = train_datagen_ResNet50_1.flow_from_directory(Train_dir,\n",
        "                                                    target_size = (140, 90),\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    shuffle=True\n",
        "                                                    )\n",
        "\n",
        "validation_genrator_ResNet50_1 = validation_datagen_ResNet50_1.flow_from_directory(Valid_dir, \n",
        "                                                   target_size=(140, 90),\n",
        "                                                   batch_size = 181,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=True)\n",
        " \n",
        "test_generator_ResNet50_1 = test_datagen_ResNet50_1.flow_from_directory(Test_dir, \n",
        "                                                  target_size = (140, 90),\n",
        "                                                  batch_size = 171 ,\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 788 images belonging to 6 classes.\n",
            "Found 181 images belonging to 6 classes.\n",
            "Found 171 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsEkHkFpxs6F",
        "colab_type": "code",
        "outputId": "b3dfa347-7799-4825-b83f-79ec30d7344f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "K.clear_session()\n",
        "resnet50_model_1 = models.Sequential()\n",
        "resnet50_model_1.add(resnet_model)\n",
        "resnet50_model_1.add(layers.Flatten())\n",
        "resnet50_model_1.add(layers.Dense(256, activation='relu'))\n",
        "resnet50_model_1.add(layers.Dropout(0.5))\n",
        "resnet50_model_1.add(layers.Dense(6, activation='sigmoid'))\n",
        "\n",
        "resnet50_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 5, 3, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30720)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               7864576   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 1542      \n",
            "=================================================================\n",
            "Total params: 31,453,830\n",
            "Trainable params: 7,866,118\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTqWvGdeyD2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_g = ModelCheckpoint(filepath = 'my_best_model.hdf3', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "callback_h = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF3HSRxryJR8",
        "colab_type": "code",
        "outputId": "772ec009-440e-4266-a302-86453b056a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet50_model_1.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_resnet50_1 = resnet50_model_1.fit_generator(train_generator_ResNet50_1, \n",
        "                                    steps_per_epoch=100,\n",
        "                                    epochs=100,\n",
        "                                    callbacks=[callback_g, callback_h],\n",
        "                                    validation_data=validation_genrator_ResNet50_1,\n",
        "                                    validation_steps=valid_images.shape[0] / 10\n",
        "                                  )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5069 - accuracy: 0.1847\n",
            "Epoch 00001: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.5069 - accuracy: 0.1847 - val_loss: 0.4490 - val_accuracy: 0.1768\n",
            "Epoch 2/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4745 - accuracy: 0.2071\n",
            "Epoch 00002: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.4744 - accuracy: 0.2077 - val_loss: 0.4417 - val_accuracy: 0.3812\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.2232\n",
            "Epoch 00003: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4702 - accuracy: 0.2232 - val_loss: 0.4352 - val_accuracy: 0.3039\n",
            "Epoch 4/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4580 - accuracy: 0.2638\n",
            "Epoch 00004: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.4575 - accuracy: 0.2648 - val_loss: 0.4275 - val_accuracy: 0.3702\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4553 - accuracy: 0.2556\n",
            "Epoch 00005: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.4553 - accuracy: 0.2556 - val_loss: 0.4162 - val_accuracy: 0.3757\n",
            "Epoch 6/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4503 - accuracy: 0.2802\n",
            "Epoch 00006: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.4503 - accuracy: 0.2800 - val_loss: 0.4064 - val_accuracy: 0.3591\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4388 - accuracy: 0.3006\n",
            "Epoch 00007: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.4388 - accuracy: 0.3006 - val_loss: 0.3947 - val_accuracy: 0.4199\n",
            "Epoch 8/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4323 - accuracy: 0.3113\n",
            "Epoch 00008: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.4325 - accuracy: 0.3106 - val_loss: 0.3988 - val_accuracy: 0.3757\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.3173\n",
            "Epoch 00009: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.4268 - accuracy: 0.3173 - val_loss: 0.3744 - val_accuracy: 0.4199\n",
            "Epoch 10/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4199 - accuracy: 0.3410\n",
            "Epoch 00010: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.4203 - accuracy: 0.3406 - val_loss: 0.3764 - val_accuracy: 0.4088\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4142 - accuracy: 0.3360\n",
            "Epoch 00011: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.4142 - accuracy: 0.3360 - val_loss: 0.3655 - val_accuracy: 0.4309\n",
            "Epoch 12/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4175 - accuracy: 0.3359\n",
            "Epoch 00012: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.4178 - accuracy: 0.3355 - val_loss: 0.3646 - val_accuracy: 0.4641\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4143 - accuracy: 0.3573\n",
            "Epoch 00013: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.4143 - accuracy: 0.3573 - val_loss: 0.3642 - val_accuracy: 0.4199\n",
            "Epoch 14/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4049 - accuracy: 0.3461\n",
            "Epoch 00014: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.4047 - accuracy: 0.3452 - val_loss: 0.3534 - val_accuracy: 0.4309\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4075 - accuracy: 0.3537\n",
            "Epoch 00015: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.4075 - accuracy: 0.3537 - val_loss: 0.3548 - val_accuracy: 0.4420\n",
            "Epoch 16/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4000 - accuracy: 0.3615\n",
            "Epoch 00016: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.4000 - accuracy: 0.3610 - val_loss: 0.3540 - val_accuracy: 0.4475\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.3502\n",
            "Epoch 00017: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.4083 - accuracy: 0.3502 - val_loss: 0.3526 - val_accuracy: 0.4088\n",
            "Epoch 18/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3902 - accuracy: 0.3809\n",
            "Epoch 00018: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.3907 - accuracy: 0.3803 - val_loss: 0.3459 - val_accuracy: 0.4309\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3933 - accuracy: 0.3785\n",
            "Epoch 00019: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.3933 - accuracy: 0.3785 - val_loss: 0.3470 - val_accuracy: 0.4475\n",
            "Epoch 20/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3953 - accuracy: 0.3681\n",
            "Epoch 00020: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.3938 - accuracy: 0.3697 - val_loss: 0.3525 - val_accuracy: 0.4365\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.3654\n",
            "Epoch 00021: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.3914 - accuracy: 0.3654 - val_loss: 0.3447 - val_accuracy: 0.4751\n",
            "Epoch 22/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3931 - accuracy: 0.3691\n",
            "Epoch 00022: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.3926 - accuracy: 0.3697 - val_loss: 0.3357 - val_accuracy: 0.4917\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.3942\n",
            "Epoch 00023: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.3853 - accuracy: 0.3942 - val_loss: 0.3389 - val_accuracy: 0.4530\n",
            "Epoch 24/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3992 - accuracy: 0.3461\n",
            "Epoch 00024: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.3997 - accuracy: 0.3457 - val_loss: 0.3700 - val_accuracy: 0.4088\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3896 - accuracy: 0.3841\n",
            "Epoch 00025: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.3896 - accuracy: 0.3841 - val_loss: 0.3351 - val_accuracy: 0.4641\n",
            "Epoch 26/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3827 - accuracy: 0.3901\n",
            "Epoch 00026: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3827 - accuracy: 0.3900 - val_loss: 0.3330 - val_accuracy: 0.4807\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.3750\n",
            "Epoch 00027: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.3824 - accuracy: 0.3750 - val_loss: 0.3333 - val_accuracy: 0.4862\n",
            "Epoch 28/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.3809\n",
            "Epoch 00028: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.3817 - accuracy: 0.3798 - val_loss: 0.3405 - val_accuracy: 0.4586\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.3831\n",
            "Epoch 00029: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3812 - accuracy: 0.3831 - val_loss: 0.3225 - val_accuracy: 0.4641\n",
            "Epoch 30/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.3983\n",
            "Epoch 00030: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.3807 - accuracy: 0.3977 - val_loss: 0.3386 - val_accuracy: 0.4917\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3701 - accuracy: 0.3998\n",
            "Epoch 00031: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.3701 - accuracy: 0.3998 - val_loss: 0.3323 - val_accuracy: 0.4917\n",
            "Epoch 32/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3781 - accuracy: 0.3839\n",
            "Epoch 00032: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3779 - accuracy: 0.3839 - val_loss: 0.3254 - val_accuracy: 0.5028\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.3846\n",
            "Epoch 00033: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 14s 137ms/step - loss: 0.3786 - accuracy: 0.3846 - val_loss: 0.3193 - val_accuracy: 0.5028\n",
            "Epoch 34/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3717 - accuracy: 0.3962\n",
            "Epoch 00034: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.3714 - accuracy: 0.3966 - val_loss: 0.3305 - val_accuracy: 0.4917\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.3790\n",
            "Epoch 00035: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.3806 - accuracy: 0.3790 - val_loss: 0.3283 - val_accuracy: 0.4586\n",
            "Epoch 36/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.3594\n",
            "Epoch 00036: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.3816 - accuracy: 0.3595 - val_loss: 0.3385 - val_accuracy: 0.5083\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.3669\n",
            "Epoch 00037: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.3842 - accuracy: 0.3669 - val_loss: 0.3314 - val_accuracy: 0.5028\n",
            "Epoch 38/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3804 - accuracy: 0.3732\n",
            "Epoch 00038: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.3809 - accuracy: 0.3732 - val_loss: 0.3363 - val_accuracy: 0.4807\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3899 - accuracy: 0.3456\n",
            "Epoch 00039: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.3899 - accuracy: 0.3456 - val_loss: 0.3295 - val_accuracy: 0.4917\n",
            "Epoch 40/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.3569\n",
            "Epoch 00040: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3846 - accuracy: 0.3569 - val_loss: 0.3322 - val_accuracy: 0.4751\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3751 - accuracy: 0.3750\n",
            "Epoch 00041: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.3751 - accuracy: 0.3750 - val_loss: 0.3221 - val_accuracy: 0.5138\n",
            "Epoch 42/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.3640\n",
            "Epoch 00042: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.3798 - accuracy: 0.3646 - val_loss: 0.3288 - val_accuracy: 0.4530\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3783 - accuracy: 0.3760\n",
            "Epoch 00043: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.3783 - accuracy: 0.3760 - val_loss: 0.3339 - val_accuracy: 0.5028\n",
            "Epoch 44/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.3548\n",
            "Epoch 00044: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.3864 - accuracy: 0.3554 - val_loss: 0.3555 - val_accuracy: 0.4917\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3939 - accuracy: 0.3679\n",
            "Epoch 00045: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3939 - accuracy: 0.3679 - val_loss: 0.3450 - val_accuracy: 0.4696\n",
            "Epoch 46/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.3722\n",
            "Epoch 00046: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3883 - accuracy: 0.3717 - val_loss: 0.3496 - val_accuracy: 0.5028\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3875 - accuracy: 0.3775\n",
            "Epoch 00047: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.3875 - accuracy: 0.3775 - val_loss: 0.3445 - val_accuracy: 0.4862\n",
            "Epoch 48/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.3671\n",
            "Epoch 00048: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.3921 - accuracy: 0.3661 - val_loss: 0.3407 - val_accuracy: 0.4862\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.3679\n",
            "Epoch 00049: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3887 - accuracy: 0.3679 - val_loss: 0.3544 - val_accuracy: 0.4475\n",
            "Epoch 50/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3869 - accuracy: 0.3839\n",
            "Epoch 00050: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.3868 - accuracy: 0.3834 - val_loss: 0.3356 - val_accuracy: 0.5249\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.3477\n",
            "Epoch 00051: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.3923 - accuracy: 0.3477 - val_loss: 0.3409 - val_accuracy: 0.5028\n",
            "Epoch 52/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.3850 - accuracy: 0.3768\n",
            "Epoch 00052: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.3837 - accuracy: 0.3783 - val_loss: 0.3416 - val_accuracy: 0.4917\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.3730\n",
            "Epoch 00053: val_loss did not improve from 0.20323\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3835 - accuracy: 0.3730 - val_loss: 0.3506 - val_accuracy: 0.4862\n",
            "Epoch 00053: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8LYSZlP1Yr4",
        "colab_type": "code",
        "outputId": "8624b5b6-f6a3-4a48-c91c-60df0620b92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history_resnet50_1.history['accuracy'])\n",
        "plt.plot(history_resnet50_1.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_resnet50_1.history['loss'])\n",
        "plt.plot(history_resnet50_1.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'lower left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOuB8G6O1pNs",
        "colab_type": "code",
        "outputId": "2fc52f6c-f022-4268-9913-33a0dc648ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "validation_loss_Res_1, validation_acc_Res_1 = resnet50_model_1.evaluate_generator(validation_genrator_ResNet50, steps=10)\n",
        "print( 'validation_acc:', validation_acc_Res_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation_acc: 0.4861878454685211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEL7tG1M1vBH",
        "colab_type": "code",
        "outputId": "8fad1f59-3066-482d-a8c6-50aca0d7dbe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_loss_Res_1, test_acc_Res_1 = resnet50_model_1.evaluate_generator(test_generator_ResNet50, steps=30)\n",
        "print('test_acc:', test_acc_Res_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.5438596606254578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ato9LxLCzqo8",
        "colab_type": "text"
      },
      "source": [
        "## **Inception Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8QI7XXZjDSz",
        "colab_type": "code",
        "outputId": "69909789-850c-4722-d620-8635d1c1dc52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen_inception = ImageDataGenerator(rotation_range=20,\n",
        "                               width_shift_range=0.2,\n",
        "                               height_shift_range=0.2,\n",
        "                               shear_range=0.2,\n",
        "                               zoom_range=0.2,\n",
        "                               horizontal_flip=True,\n",
        "                               rescale=1./255,\n",
        "                               fill_mode='nearest')\n",
        "\n",
        "validation_datagen_inception = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen_inception = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator_inception = train_datagen_inception.flow_from_directory(Train_dir,\n",
        "                                                    target_size = (140, 90),\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    shuffle=True\n",
        "                                                    )\n",
        "\n",
        "validation_genrator_inception = validation_datagen_inception.flow_from_directory(Valid_dir, \n",
        "                                                   target_size=(140, 90),\n",
        "                                                   batch_size = 181,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=True)\n",
        " \n",
        "test_generator_inception = test_datagen_inception.flow_from_directory(Test_dir, \n",
        "                                                  target_size = (140, 90),\n",
        "                                                  batch_size = 171,\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 788 images belonging to 6 classes.\n",
            "Found 181 images belonging to 6 classes.\n",
            "Found 171 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dl-DfYFd09m",
        "colab_type": "code",
        "outputId": "97085604-0998-4da7-eb23-45e4100f4238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "\n",
        "inception_model =InceptionV3(weights='imagenet', include_top = False, input_shape = (140,90, 3))\n",
        "inception_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 140, 90, 3)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 69, 44, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 69, 44, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 69, 44, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 67, 42, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 67, 42, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 67, 42, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 67, 42, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 67, 42, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 67, 42, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 33, 20, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 33, 20, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 33, 20, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 33, 20, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 31, 18, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 31, 18, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 31, 18, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 15, 8, 192)   0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 15, 8, 64)    12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 15, 8, 64)    192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 15, 8, 64)    0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 15, 8, 48)    9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 15, 8, 96)    55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 15, 8, 48)    144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 15, 8, 96)    288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 15, 8, 48)    0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 15, 8, 96)    0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 15, 8, 192)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 15, 8, 64)    12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 15, 8, 64)    76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 15, 8, 96)    82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 15, 8, 32)    6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 15, 8, 64)    192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 15, 8, 64)    192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 15, 8, 96)    288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 15, 8, 32)    96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 15, 8, 64)    0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 15, 8, 64)    0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 15, 8, 96)    0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 15, 8, 32)    0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 15, 8, 256)   0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 15, 8, 64)    16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 15, 8, 64)    192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 15, 8, 64)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 15, 8, 48)    12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 15, 8, 96)    55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 15, 8, 48)    144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 15, 8, 96)    288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 15, 8, 48)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 15, 8, 96)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 15, 8, 256)   0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 15, 8, 64)    16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 15, 8, 64)    76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 15, 8, 96)    82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 15, 8, 64)    16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 15, 8, 64)    192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 15, 8, 64)    192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 15, 8, 96)    288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 15, 8, 64)    192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 15, 8, 64)    0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 15, 8, 64)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 15, 8, 96)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 15, 8, 64)    0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 15, 8, 288)   0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 15, 8, 64)    18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 15, 8, 64)    192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 15, 8, 64)    0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 15, 8, 48)    13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 15, 8, 96)    55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 15, 8, 48)    144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 15, 8, 96)    288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 15, 8, 48)    0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 15, 8, 96)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 15, 8, 288)   0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 15, 8, 64)    18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 15, 8, 64)    76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 15, 8, 96)    82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 15, 8, 64)    18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 15, 8, 64)    192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 15, 8, 64)    192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 15, 8, 96)    288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 15, 8, 64)    192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 15, 8, 64)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 15, 8, 64)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 15, 8, 96)    0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 15, 8, 64)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 15, 8, 288)   0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 15, 8, 64)    18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 15, 8, 64)    192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 15, 8, 64)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 15, 8, 96)    55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 15, 8, 96)    288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 15, 8, 96)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 3, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 3, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 3, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 3, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 3, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 3, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 3, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 3, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 3, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 3, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 3, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 3, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 3, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 3, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 3, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 3, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 3, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 3, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 3, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 3, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 3, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 3, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 3, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 3, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 3, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 3, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 3, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 3, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 3, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 3, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 3, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 3, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 3, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 3, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 3, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 3, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 3, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 3, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 3, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 3, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 3, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 3, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 3, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 3, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 3, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 3, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 3, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 3, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 3, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 3, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 3, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 3, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 3, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 3, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 3, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 3, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 3, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 3, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 3, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 3, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 3, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 3, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 3, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 3, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 3, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 3, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 3, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 3, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 3, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 3, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 3, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 3, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 3, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 3, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 3, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 3, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 3, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 3, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 3, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 3, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 3, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 3, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 3, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 3, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 3, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 3, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 3, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 3, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 3, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 3, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 3, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 3, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 3, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 3, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 3, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 3, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 3, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 3, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 3, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 3, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 3, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 3, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 3, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 3, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 3, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 3, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 3, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 3, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 3, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 3, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 3, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 3, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 3, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 3, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 3, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 3, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 3, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 3, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 3, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 3, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 3, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 3, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 3, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 3, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 3, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 3, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 3, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 3, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 3, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 3, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 3, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 3, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 3, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 3, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 3, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 3, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 3, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 3, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 3, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 3, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 3, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 3, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 3, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 3, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 3, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 3, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 1, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 1, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 1, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 1, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 1, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 1, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 1, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 1, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 1, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 1, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 1, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 1, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 1, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 1, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 1, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 1, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 1, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 1, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 1, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 1, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 1, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 1, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 1, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 1, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 1, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 1, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 1, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 1, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 1, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 1, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 1, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 1, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 1, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 1, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 1, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 1, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 1, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 1, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 1, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 1, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 1, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 1, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 1, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 1, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 1, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 1, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 1, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 1, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 1, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 1, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 1, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 1, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 1, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 1, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 1, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 1, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 1, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 1, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 1, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 1, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 1, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 1, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 1, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 1, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 1, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 1, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 1, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 1, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 1, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 1, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FcGOwptiXDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in inception_model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS8ity4pygDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "x = layers.Flatten()(inception_model.output)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_inception = Model(inception_model.input, x)\n",
        "model_inception.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l_SrAsjzTnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_I = ModelCheckpoint(filepath = 'my_best_model.hdf5', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "callback_J = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ5a7Fe734Se",
        "colab_type": "code",
        "outputId": "fa6af472-8aaf-437e-e40c-cd4557e810ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_inception = model_inception.fit_generator(train_generator_inception,\n",
        "                                                  steps_per_epoch=100,\n",
        "                                                  epochs=100,\n",
        "                                                  callbacks=[callback_I, callback_J], \n",
        "                                                  validation_data=validation_genrator_inception,\n",
        "                                                  validation_steps=valid_images.shape[0] / 10                             \n",
        "                                                )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.8269\n",
            "Epoch 00001: val_loss improved from inf to 0.45510, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.5653 - accuracy: 0.8269 - val_loss: 0.4551 - val_accuracy: 0.8333\n",
            "Epoch 2/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4558 - accuracy: 0.8333\n",
            "Epoch 00002: val_loss improved from 0.45510 to 0.45468, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.4558 - accuracy: 0.8333 - val_loss: 0.4547 - val_accuracy: 0.8333\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4542 - accuracy: 0.8333\n",
            "Epoch 00003: val_loss improved from 0.45468 to 0.45355, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4542 - accuracy: 0.8333 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
            "Epoch 4/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4536 - accuracy: 0.8333\n",
            "Epoch 00004: val_loss improved from 0.45355 to 0.45229, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4535 - accuracy: 0.8333 - val_loss: 0.4523 - val_accuracy: 0.8333\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4534 - accuracy: 0.8333\n",
            "Epoch 00005: val_loss did not improve from 0.45229\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.4534 - accuracy: 0.8333 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
            "Epoch 6/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4528 - accuracy: 0.8333\n",
            "Epoch 00006: val_loss improved from 0.45229 to 0.45207, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.4528 - accuracy: 0.8333 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4529 - accuracy: 0.8333\n",
            "Epoch 00007: val_loss did not improve from 0.45207\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.4529 - accuracy: 0.8333 - val_loss: 0.4543 - val_accuracy: 0.8333\n",
            "Epoch 8/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4526 - accuracy: 0.8333\n",
            "Epoch 00008: val_loss did not improve from 0.45207\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.4526 - accuracy: 0.8333 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.8333\n",
            "Epoch 00009: val_loss improved from 0.45207 to 0.45173, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.4525 - accuracy: 0.8333 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
            "Epoch 10/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4523 - accuracy: 0.8333\n",
            "Epoch 00010: val_loss did not improve from 0.45173\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.4523 - accuracy: 0.8333 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4521 - accuracy: 0.8333\n",
            "Epoch 00011: val_loss did not improve from 0.45173\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.4521 - accuracy: 0.8333 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
            "Epoch 12/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4520 - accuracy: 0.8333\n",
            "Epoch 00012: val_loss improved from 0.45173 to 0.45149, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.4520 - accuracy: 0.8333 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4520 - accuracy: 0.8333\n",
            "Epoch 00013: val_loss did not improve from 0.45149\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.4520 - accuracy: 0.8333 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
            "Epoch 14/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4519 - accuracy: 0.8333\n",
            "Epoch 00014: val_loss did not improve from 0.45149\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.4519 - accuracy: 0.8333 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4520 - accuracy: 0.8333\n",
            "Epoch 00015: val_loss did not improve from 0.45149\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.4520 - accuracy: 0.8333 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
            "Epoch 16/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4519 - accuracy: 0.8333\n",
            "Epoch 00016: val_loss did not improve from 0.45149\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.4519 - accuracy: 0.8333 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4518 - accuracy: 0.8333\n",
            "Epoch 00017: val_loss did not improve from 0.45149\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.4518 - accuracy: 0.8333 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
            "Epoch 18/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4518 - accuracy: 0.8333\n",
            "Epoch 00018: val_loss improved from 0.45149 to 0.45132, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.4518 - accuracy: 0.8333 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.8333\n",
            "Epoch 00019: val_loss did not improve from 0.45132\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.4516 - accuracy: 0.8333 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
            "Epoch 20/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4518 - accuracy: 0.8333\n",
            "Epoch 00020: val_loss improved from 0.45132 to 0.45125, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.4518 - accuracy: 0.8333 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.8333\n",
            "Epoch 00021: val_loss did not improve from 0.45125\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.4516 - accuracy: 0.8333 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
            "Epoch 22/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4515 - accuracy: 0.8333\n",
            "Epoch 00022: val_loss did not improve from 0.45125\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.4515 - accuracy: 0.8333 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.8333\n",
            "Epoch 00023: val_loss improved from 0.45125 to 0.45114, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.4515 - accuracy: 0.8333 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
            "Epoch 24/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4514 - accuracy: 0.8333\n",
            "Epoch 00024: val_loss did not improve from 0.45114\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.4514 - accuracy: 0.8333 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.8333\n",
            "Epoch 00025: val_loss did not improve from 0.45114\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.4514 - accuracy: 0.8333 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
            "Epoch 26/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4514 - accuracy: 0.8333\n",
            "Epoch 00026: val_loss did not improve from 0.45114\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.4514 - accuracy: 0.8333 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.8333\n",
            "Epoch 00027: val_loss did not improve from 0.45114\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.4514 - accuracy: 0.8333 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
            "Epoch 28/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4514 - accuracy: 0.8333\n",
            "Epoch 00028: val_loss did not improve from 0.45114\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4514 - accuracy: 0.8333 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.8333\n",
            "Epoch 00029: val_loss did not improve from 0.45114\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.4515 - accuracy: 0.8333 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
            "Epoch 30/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4515 - accuracy: 0.8333\n",
            "Epoch 00030: val_loss did not improve from 0.45114\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4515 - accuracy: 0.8333 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.8333\n",
            "Epoch 00031: val_loss did not improve from 0.45114\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.4513 - accuracy: 0.8333 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
            "Epoch 32/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4512 - accuracy: 0.8333\n",
            "Epoch 00032: val_loss improved from 0.45114 to 0.45098, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.4512 - accuracy: 0.8333 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4512 - accuracy: 0.8333\n",
            "Epoch 00033: val_loss did not improve from 0.45098\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.4512 - accuracy: 0.8333 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
            "Epoch 34/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4512 - accuracy: 0.8333\n",
            "Epoch 00034: val_loss did not improve from 0.45098\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4512 - accuracy: 0.8333 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4512 - accuracy: 0.8333\n",
            "Epoch 00035: val_loss improved from 0.45098 to 0.45098, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.4512 - accuracy: 0.8333 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
            "Epoch 36/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4512 - accuracy: 0.8333\n",
            "Epoch 00036: val_loss did not improve from 0.45098\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.4512 - accuracy: 0.8333 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.8333\n",
            "Epoch 00037: val_loss did not improve from 0.45098\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.4511 - accuracy: 0.8333 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
            "Epoch 38/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4512 - accuracy: 0.8333\n",
            "Epoch 00038: val_loss improved from 0.45098 to 0.45097, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.4512 - accuracy: 0.8333 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.8333\n",
            "Epoch 00039: val_loss improved from 0.45097 to 0.45092, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.4511 - accuracy: 0.8333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
            "Epoch 40/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4511 - accuracy: 0.8333\n",
            "Epoch 00040: val_loss did not improve from 0.45092\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4512 - accuracy: 0.8333 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.8333\n",
            "Epoch 00041: val_loss improved from 0.45092 to 0.45091, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.4511 - accuracy: 0.8333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
            "Epoch 42/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4511 - accuracy: 0.8333\n",
            "Epoch 00042: val_loss did not improve from 0.45091\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4511 - accuracy: 0.8333 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.8333\n",
            "Epoch 00043: val_loss did not improve from 0.45091\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4511 - accuracy: 0.8333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
            "Epoch 44/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4511 - accuracy: 0.8333\n",
            "Epoch 00044: val_loss did not improve from 0.45091\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.4511 - accuracy: 0.8333 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.8333\n",
            "Epoch 00045: val_loss did not improve from 0.45091\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.4511 - accuracy: 0.8333 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
            "Epoch 46/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4510 - accuracy: 0.8333\n",
            "Epoch 00046: val_loss did not improve from 0.45091\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.4510 - accuracy: 0.8333 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4510 - accuracy: 0.8333\n",
            "Epoch 00047: val_loss did not improve from 0.45091\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4510 - accuracy: 0.8333 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
            "Epoch 48/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4510 - accuracy: 0.8333\n",
            "Epoch 00048: val_loss improved from 0.45091 to 0.45090, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.4510 - accuracy: 0.8333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4510 - accuracy: 0.8333\n",
            "Epoch 00049: val_loss improved from 0.45090 to 0.45085, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.4510 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 50/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4510 - accuracy: 0.8333\n",
            "Epoch 00050: val_loss improved from 0.45085 to 0.45085, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.4510 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4510 - accuracy: 0.8333\n",
            "Epoch 00051: val_loss did not improve from 0.45085\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.4510 - accuracy: 0.8333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
            "Epoch 52/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4509 - accuracy: 0.8333\n",
            "Epoch 00052: val_loss improved from 0.45085 to 0.45081, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.4509 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4510 - accuracy: 0.8333\n",
            "Epoch 00053: val_loss did not improve from 0.45081\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.4510 - accuracy: 0.8333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
            "Epoch 54/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4509 - accuracy: 0.8333\n",
            "Epoch 00054: val_loss did not improve from 0.45081\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.4509 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.8333\n",
            "Epoch 00055: val_loss did not improve from 0.45081\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.4509 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 56/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4509 - accuracy: 0.8333\n",
            "Epoch 00056: val_loss did not improve from 0.45081\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.4509 - accuracy: 0.8333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.8333\n",
            "Epoch 00057: val_loss improved from 0.45081 to 0.45075, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 14s 139ms/step - loss: 0.4509 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 58/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4509 - accuracy: 0.8333\n",
            "Epoch 00058: val_loss did not improve from 0.45075\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.4509 - accuracy: 0.8333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.8333\n",
            "Epoch 00059: val_loss did not improve from 0.45075\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.4509 - accuracy: 0.8333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
            "Epoch 60/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4509 - accuracy: 0.8333\n",
            "Epoch 00060: val_loss did not improve from 0.45075\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.4509 - accuracy: 0.8333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.8333\n",
            "Epoch 00061: val_loss did not improve from 0.45075\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4508 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 62/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4508 - accuracy: 0.8333\n",
            "Epoch 00062: val_loss did not improve from 0.45075\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.4508 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.8333\n",
            "Epoch 00063: val_loss improved from 0.45075 to 0.45074, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.4509 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 64/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4508 - accuracy: 0.8333\n",
            "Epoch 00064: val_loss improved from 0.45074 to 0.45072, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.4508 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.8333\n",
            "Epoch 00065: val_loss did not improve from 0.45072\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4508 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 66/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4508 - accuracy: 0.8333\n",
            "Epoch 00066: val_loss did not improve from 0.45072\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.4508 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.8333\n",
            "Epoch 00067: val_loss improved from 0.45072 to 0.45072, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.4508 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 68/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4508 - accuracy: 0.8333\n",
            "Epoch 00068: val_loss did not improve from 0.45072\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.4508 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.8333\n",
            "Epoch 00069: val_loss did not improve from 0.45072\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4508 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 70/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4508 - accuracy: 0.8333\n",
            "Epoch 00070: val_loss did not improve from 0.45072\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4508 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00071: val_loss did not improve from 0.45072\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 72/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00072: val_loss did not improve from 0.45072\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00073: val_loss improved from 0.45072 to 0.45067, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 74/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4508 - accuracy: 0.8333\n",
            "Epoch 00074: val_loss did not improve from 0.45067\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4508 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00075: val_loss did not improve from 0.45067\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 76/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00076: val_loss improved from 0.45067 to 0.45066, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00077: val_loss improved from 0.45066 to 0.45065, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 78/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00078: val_loss did not improve from 0.45065\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00079: val_loss did not improve from 0.45065\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 80/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00080: val_loss improved from 0.45065 to 0.45065, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00081: val_loss improved from 0.45065 to 0.45065, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 82/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00082: val_loss did not improve from 0.45065\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00083: val_loss did not improve from 0.45065\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 84/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00084: val_loss improved from 0.45065 to 0.45064, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00085: val_loss improved from 0.45064 to 0.45063, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 86/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00086: val_loss did not improve from 0.45063\n",
            "100/100 [==============================] - 12s 120ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00087: val_loss improved from 0.45063 to 0.45061, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 88/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00088: val_loss did not improve from 0.45061\n",
            "100/100 [==============================] - 12s 120ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00089: val_loss improved from 0.45061 to 0.45061, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 90/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00090: val_loss did not improve from 0.45061\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00091: val_loss did not improve from 0.45061\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 92/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00092: val_loss did not improve from 0.45061\n",
            "100/100 [==============================] - 12s 120ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00093: val_loss did not improve from 0.45061\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 94/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00094: val_loss improved from 0.45061 to 0.45060, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00095: val_loss did not improve from 0.45060\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 96/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00096: val_loss did not improve from 0.45060\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00097: val_loss did not improve from 0.45060\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 98/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00098: val_loss improved from 0.45060 to 0.45059, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 12s 125ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00099: val_loss did not improve from 0.45059\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 100/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00100: val_loss improved from 0.45059 to 0.45059, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95fJ840K7Njw",
        "colab_type": "code",
        "outputId": "26147827-0013-4c81-ac41-4166635d12fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "plt.plot(history_inception.history['accuracy'])\n",
        "plt.plot(history_inception.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_inception.history['loss'])\n",
        "plt.plot(history_inception.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'lower left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y93S62P57Wa3",
        "colab_type": "code",
        "outputId": "be76d872-576e-4edd-d0b4-6241132651e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "validation_loss_Incept, validation_acc_Incept = model_inception.evaluate_generator(validation_genrator_inception, steps=10)\n",
        "print( 'validation_acc:', validation_acc_Incept)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation_acc: 0.6602209806442261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmDNC64l7kKA",
        "colab_type": "code",
        "outputId": "24db3922-3ef7-4ab1-eb18-1ffa82ef162d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_loss_incept, test_acc_incept = model_inception.evaluate_generator(test_generator_inception, steps=30)\n",
        "print('test_acc:', test_acc_Res_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.5438596606254578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CmkXoo82TRt",
        "colab_type": "text"
      },
      "source": [
        "### **Inception with regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARWdIBuQ6u5R",
        "colab_type": "code",
        "outputId": "3ca0bdf8-778b-4373-b0c4-5c7ee6f92b94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen_inception_1 = ImageDataGenerator(rotation_range=20,\n",
        "                               width_shift_range=0.2,\n",
        "                               height_shift_range=0.2,\n",
        "                               shear_range=0.2,\n",
        "                               zoom_range=0.2,\n",
        "                               horizontal_flip=True,\n",
        "                               rescale=1./255,\n",
        "                               fill_mode='nearest')\n",
        "\n",
        "validation_datagen_inception_1 = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen_inception_1 = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator_inception_1 = train_datagen_inception_1.flow_from_directory(Train_dir,\n",
        "                                                    target_size = (140, 90),\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    shuffle=True\n",
        "                                                    )\n",
        "\n",
        "validation_genrator_inception_1 = validation_datagen_inception_1.flow_from_directory(Valid_dir, \n",
        "                                                   target_size=(140, 90),\n",
        "                                                   batch_size = 181,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=True)\n",
        " \n",
        "test_generator_inception_1 = test_datagen_inception_1.flow_from_directory(Test_dir, \n",
        "                                                  target_size = (140, 90),\n",
        "                                                  batch_size = 171,\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 788 images belonging to 6 classes.\n",
            "Found 181 images belonging to 6 classes.\n",
            "Found 171 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gImr5-X616e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "x_1 = layers.Flatten()(inception_model.output)\n",
        "x_1 = layers.Dense(256, activation='relu')(x_1)\n",
        "x_1 = layers.Dropout(0.5)(x_1)\n",
        "x_1 = layers.Dense(1, activation='sigmoid')(x_1)\n",
        "\n",
        "model_inception_1 = Model(inception_model.input, x_1)\n",
        "model_inception_1.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK56OCjZ8Vey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_K = ModelCheckpoint(filepath = 'my_best_model.hdf5', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "callback_L = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svXsVxL-8cpA",
        "colab_type": "code",
        "outputId": "4eee0555-434b-4461-eb63-edb1cb50c3c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history_inception_1 = model_inception_1.fit_generator(train_generator_inception_1,\n",
        "                                                  steps_per_epoch=100,\n",
        "                                                  epochs=100,\n",
        "                                                  callbacks=[callback_K, callback_L], \n",
        "                                                  validation_data=validation_genrator_inception_1,\n",
        "                                                  validation_steps=valid_images.shape[0] / 10                             \n",
        "                                                )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-b6b48101dc3b>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6619 - accuracy: 0.8043\n",
            "Epoch 00001: val_loss improved from inf to 0.45602, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.6619 - accuracy: 0.8043 - val_loss: 0.4560 - val_accuracy: 0.8333\n",
            "Epoch 2/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4739 - accuracy: 0.8333\n",
            "Epoch 00002: val_loss improved from 0.45602 to 0.45555, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.4738 - accuracy: 0.8333 - val_loss: 0.4556 - val_accuracy: 0.8333\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4704 - accuracy: 0.8333\n",
            "Epoch 00003: val_loss improved from 0.45555 to 0.45449, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.4704 - accuracy: 0.8333 - val_loss: 0.4545 - val_accuracy: 0.8333\n",
            "Epoch 4/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4684 - accuracy: 0.8333\n",
            "Epoch 00004: val_loss improved from 0.45449 to 0.45447, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.4685 - accuracy: 0.8333 - val_loss: 0.4545 - val_accuracy: 0.8333\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.8333\n",
            "Epoch 00005: val_loss improved from 0.45447 to 0.45299, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.4657 - accuracy: 0.8333 - val_loss: 0.4530 - val_accuracy: 0.8333\n",
            "Epoch 6/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4655 - accuracy: 0.8330\n",
            "Epoch 00006: val_loss improved from 0.45299 to 0.45208, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.4653 - accuracy: 0.8330 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4634 - accuracy: 0.8333\n",
            "Epoch 00007: val_loss did not improve from 0.45208\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.4634 - accuracy: 0.8333 - val_loss: 0.4526 - val_accuracy: 0.8333\n",
            "Epoch 8/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4627 - accuracy: 0.8333\n",
            "Epoch 00008: val_loss did not improve from 0.45208\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.4629 - accuracy: 0.8333 - val_loss: 0.4524 - val_accuracy: 0.8333\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4611 - accuracy: 0.8333\n",
            "Epoch 00009: val_loss improved from 0.45208 to 0.45201, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.4611 - accuracy: 0.8333 - val_loss: 0.4520 - val_accuracy: 0.8333\n",
            "Epoch 10/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4594 - accuracy: 0.8333\n",
            "Epoch 00010: val_loss improved from 0.45201 to 0.45185, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.4593 - accuracy: 0.8333 - val_loss: 0.4519 - val_accuracy: 0.8333\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4590 - accuracy: 0.8333\n",
            "Epoch 00011: val_loss improved from 0.45185 to 0.45163, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 185ms/step - loss: 0.4590 - accuracy: 0.8333 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
            "Epoch 12/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4584 - accuracy: 0.8333\n",
            "Epoch 00012: val_loss improved from 0.45163 to 0.45151, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.4584 - accuracy: 0.8333 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.8333\n",
            "Epoch 00013: val_loss did not improve from 0.45151\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.4577 - accuracy: 0.8333 - val_loss: 0.4517 - val_accuracy: 0.8333\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4574 - accuracy: 0.8333\n",
            "Epoch 00014: val_loss improved from 0.45151 to 0.45143, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.4574 - accuracy: 0.8333 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.8333\n",
            "Epoch 00015: val_loss did not improve from 0.45143\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.4565 - accuracy: 0.8333 - val_loss: 0.4539 - val_accuracy: 0.8333\n",
            "Epoch 16/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4560 - accuracy: 0.8333\n",
            "Epoch 00016: val_loss improved from 0.45143 to 0.45135, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.4560 - accuracy: 0.8333 - val_loss: 0.4514 - val_accuracy: 0.8333\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.8333\n",
            "Epoch 00017: val_loss did not improve from 0.45135\n",
            "100/100 [==============================] - 17s 171ms/step - loss: 0.4557 - accuracy: 0.8333 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
            "Epoch 18/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4553 - accuracy: 0.8333\n",
            "Epoch 00018: val_loss did not improve from 0.45135\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.4553 - accuracy: 0.8333 - val_loss: 0.4515 - val_accuracy: 0.8333\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4549 - accuracy: 0.8333\n",
            "Epoch 00019: val_loss improved from 0.45135 to 0.45115, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 19s 190ms/step - loss: 0.4549 - accuracy: 0.8333 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
            "Epoch 20/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4548 - accuracy: 0.8333\n",
            "Epoch 00020: val_loss did not improve from 0.45115\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.4549 - accuracy: 0.8333 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4545 - accuracy: 0.8333\n",
            "Epoch 00021: val_loss did not improve from 0.45115\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.4545 - accuracy: 0.8333 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
            "Epoch 22/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4539 - accuracy: 0.8333\n",
            "Epoch 00022: val_loss improved from 0.45115 to 0.45107, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.4538 - accuracy: 0.8333 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4535 - accuracy: 0.8333\n",
            "Epoch 00023: val_loss did not improve from 0.45107\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.4535 - accuracy: 0.8333 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
            "Epoch 24/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4536 - accuracy: 0.8333\n",
            "Epoch 00024: val_loss improved from 0.45107 to 0.45092, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.4536 - accuracy: 0.8333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.8333\n",
            "Epoch 00025: val_loss did not improve from 0.45092\n",
            "100/100 [==============================] - 19s 185ms/step - loss: 0.4531 - accuracy: 0.8333 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
            "Epoch 26/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4529 - accuracy: 0.8333\n",
            "Epoch 00026: val_loss improved from 0.45092 to 0.45081, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.4529 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4527 - accuracy: 0.8333\n",
            "Epoch 00027: val_loss did not improve from 0.45081\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.4527 - accuracy: 0.8333 - val_loss: 0.4510 - val_accuracy: 0.8333\n",
            "Epoch 28/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4524 - accuracy: 0.8333\n",
            "Epoch 00028: val_loss did not improve from 0.45081\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.4524 - accuracy: 0.8333 - val_loss: 0.4509 - val_accuracy: 0.8333\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.8333\n",
            "Epoch 00029: val_loss did not improve from 0.45081\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.4523 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 30/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4523 - accuracy: 0.8333\n",
            "Epoch 00030: val_loss improved from 0.45081 to 0.45075, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.4523 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4520 - accuracy: 0.8333\n",
            "Epoch 00031: val_loss did not improve from 0.45075\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.4520 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 32/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4520 - accuracy: 0.8333\n",
            "Epoch 00032: val_loss did not improve from 0.45075\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.4520 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4518 - accuracy: 0.8333\n",
            "Epoch 00033: val_loss improved from 0.45075 to 0.45071, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.4518 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 34/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4517 - accuracy: 0.8333\n",
            "Epoch 00034: val_loss improved from 0.45071 to 0.45070, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.4517 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.8333\n",
            "Epoch 00035: val_loss improved from 0.45070 to 0.45069, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.4515 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.8333\n",
            "Epoch 00036: val_loss did not improve from 0.45069\n",
            "100/100 [==============================] - 20s 201ms/step - loss: 0.4514 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.8333\n",
            "Epoch 00037: val_loss did not improve from 0.45069\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.4515 - accuracy: 0.8333 - val_loss: 0.4508 - val_accuracy: 0.8333\n",
            "Epoch 38/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4513 - accuracy: 0.8333\n",
            "Epoch 00038: val_loss improved from 0.45069 to 0.45064, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.4513 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4512 - accuracy: 0.8333\n",
            "Epoch 00039: val_loss did not improve from 0.45064\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.4512 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 40/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4511 - accuracy: 0.8333\n",
            "Epoch 00040: val_loss improved from 0.45064 to 0.45063, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.4511 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.8333\n",
            "Epoch 00041: val_loss did not improve from 0.45063\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.4511 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 42/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4510 - accuracy: 0.8333\n",
            "Epoch 00042: val_loss did not improve from 0.45063\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.4510 - accuracy: 0.8333 - val_loss: 0.4507 - val_accuracy: 0.8333\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.8333\n",
            "Epoch 00043: val_loss did not improve from 0.45063\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 0.4509 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 44/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4508 - accuracy: 0.8333\n",
            "Epoch 00044: val_loss did not improve from 0.45063\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.4508 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.8333\n",
            "Epoch 00045: val_loss improved from 0.45063 to 0.45060, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.4508 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 46/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4508 - accuracy: 0.8333\n",
            "Epoch 00046: val_loss did not improve from 0.45060\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.4508 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00047: val_loss improved from 0.45060 to 0.45058, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 48/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00048: val_loss did not improve from 0.45058\n",
            "100/100 [==============================] - 19s 185ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00049: val_loss did not improve from 0.45058\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 50/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.8333\n",
            "Epoch 00050: val_loss did not improve from 0.45058\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.4507 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00051: val_loss improved from 0.45058 to 0.45058, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 52/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00052: val_loss improved from 0.45058 to 0.45057, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00053: val_loss improved from 0.45057 to 0.45057, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 54/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00054: val_loss improved from 0.45057 to 0.45057, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00055: val_loss did not improve from 0.45057\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 56/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00056: val_loss improved from 0.45057 to 0.45056, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00057: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 58/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00058: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00059: val_loss improved from 0.45056 to 0.45056, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 60/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00060: val_loss improved from 0.45056 to 0.45056, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 20s 199ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00061: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 62/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00062: val_loss improved from 0.45056 to 0.45056, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00063: val_loss improved from 0.45056 to 0.45056, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 64/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00064: val_loss improved from 0.45056 to 0.45056, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00065: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 175ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 66/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00066: val_loss improved from 0.45056 to 0.45056, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00067: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 68/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00068: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00069: val_loss improved from 0.45056 to 0.45056, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 70/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00070: val_loss improved from 0.45056 to 0.45056, saving model to my_best_model.hdf5\n",
            "100/100 [==============================] - 20s 202ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00071: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 19s 185ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 72/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00072: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00073: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 74/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00074: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00075: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 76/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00076: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00077: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 78/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00078: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00079: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 80/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00080: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00081: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 82/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00082: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00083: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 84/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00084: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00085: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 17s 175ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 86/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00086: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00087: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 88/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00088: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00089: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 90/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8333\n",
            "Epoch 00090: val_loss did not improve from 0.45056\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.4506 - accuracy: 0.8333 - val_loss: 0.4506 - val_accuracy: 0.8333\n",
            "Epoch 00090: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO4o0UyG7EED",
        "colab_type": "code",
        "outputId": "4aed0435-e77f-46b9-d68d-9e74c1b808a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plt.plot(history_inception_1.history['accuracy'])\n",
        "plt.plot(history_inception_1.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_inception_1.history['loss'])\n",
        "plt.plot(history_inception_1.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'lower left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDv4r3ru8Kqk",
        "colab_type": "code",
        "outputId": "47a850dd-8dac-49a5-9830-199d4a723091",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "validation_loss_Incept_1, validation_acc_Incept_1 = model_inception_1.evaluate_generator(validation_genrator_inception_1, steps=10)\n",
        "print( 'validation_acc:', validation_acc_Incept_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-bd19173d3b81>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.evaluate, which supports generators.\n",
            "validation_acc: 0.8333333730697632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8DoBOdzzrUR",
        "colab_type": "code",
        "outputId": "ac01101a-54d9-4d95-8a2b-cbfc7792c444",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_loss_incept_1, test_acc_incept_1 = model_inception_1.evaluate_generator(test_generator_inception_1, steps=30)\n",
        "print('test_acc:', test_acc_incept_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.8333333134651184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0cKoqbh2INc",
        "colab_type": "text"
      },
      "source": [
        "##**DenseNet121**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKx3K2c12Hm3",
        "colab_type": "code",
        "outputId": "fbb69dbe-5122-4e3a-bbcf-ca7e80318d4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "densenet = DenseNet121(weights='imagenet', include_top=False, input_shape=(140,90,3))\n",
        "\n",
        "for layer in densenet.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz9sVAsT-EOF",
        "colab_type": "code",
        "outputId": "0ebce417-760e-45ab-c436-466700f54433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "densenet.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 140, 90, 3)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 146, 96, 3)   0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 70, 45, 64)   9408        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 70, 45, 64)   256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 70, 45, 64)   0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 72, 47, 64)   0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 35, 23, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 35, 23, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 35, 23, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 35, 23, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 35, 23, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 35, 23, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 35, 23, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 35, 23, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 35, 23, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 35, 23, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 35, 23, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 35, 23, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 35, 23, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 35, 23, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 35, 23, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 35, 23, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 35, 23, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 35, 23, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 35, 23, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 35, 23, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 35, 23, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 35, 23, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 35, 23, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 35, 23, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 35, 23, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 35, 23, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 35, 23, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 35, 23, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 35, 23, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 35, 23, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 35, 23, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 35, 23, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 35, 23, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 17, 11, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 17, 11, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 17, 11, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 17, 11, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 17, 11, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 17, 11, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 17, 11, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 17, 11, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 17, 11, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 17, 11, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 17, 11, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 17, 11, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 17, 11, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 17, 11, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 17, 11, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 17, 11, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 17, 11, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 17, 11, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 17, 11, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 17, 11, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 17, 11, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 17, 11, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 17, 11, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 17, 11, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 17, 11, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 17, 11, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 17, 11, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 17, 11, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 17, 11, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 17, 11, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 17, 11, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 17, 11, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 17, 11, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 17, 11, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 17, 11, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 17, 11, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 17, 11, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 17, 11, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 17, 11, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 17, 11, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 17, 11, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 17, 11, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 17, 11, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 17, 11, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 17, 11, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 17, 11, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 17, 11, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 17, 11, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 17, 11, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 17, 11, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 17, 11, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 17, 11, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 17, 11, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 17, 11, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 17, 11, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 17, 11, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 17, 11, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 17, 11, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 17, 11, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 17, 11, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 17, 11, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 8, 5, 256)    0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 8, 5, 256)    1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 8, 5, 256)    0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 8, 5, 128)    32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 8, 5, 128)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 8, 5, 288)    0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 8, 5, 288)    1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 8, 5, 288)    0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 8, 5, 128)    36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 8, 5, 128)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 8, 5, 320)    0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 8, 5, 320)    1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 8, 5, 320)    0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 8, 5, 128)    40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 8, 5, 128)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 8, 5, 352)    0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 8, 5, 352)    1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 8, 5, 352)    0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 8, 5, 128)    45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 8, 5, 128)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 8, 5, 384)    0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 8, 5, 384)    1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 8, 5, 384)    0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 8, 5, 128)    49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 8, 5, 128)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 8, 5, 416)    0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 8, 5, 416)    1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 8, 5, 416)    0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 8, 5, 128)    53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 8, 5, 128)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 8, 5, 448)    0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 8, 5, 448)    1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 8, 5, 448)    0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 8, 5, 128)    57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 8, 5, 128)    0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 8, 5, 480)    0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 8, 5, 480)    1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 8, 5, 480)    0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 8, 5, 128)    61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 8, 5, 128)    0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 8, 5, 512)    0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 8, 5, 512)    2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 8, 5, 512)    0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 8, 5, 128)    65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 8, 5, 128)    0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 8, 5, 544)    0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 8, 5, 544)    2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 8, 5, 544)    0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 8, 5, 128)    69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 8, 5, 576)    0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 8, 5, 576)    2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 8, 5, 576)    0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 8, 5, 128)    73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 8, 5, 608)    0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 8, 5, 608)    2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 8, 5, 608)    0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 8, 5, 128)    77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 8, 5, 640)    0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 8, 5, 640)    2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 8, 5, 640)    0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 8, 5, 128)    81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 8, 5, 672)    0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 8, 5, 672)    2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 8, 5, 672)    0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 8, 5, 128)    86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 8, 5, 704)    0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 8, 5, 704)    2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 8, 5, 704)    0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 8, 5, 128)    90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 8, 5, 736)    0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 8, 5, 736)    2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 8, 5, 736)    0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 8, 5, 128)    94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 8, 5, 768)    0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 8, 5, 768)    3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 8, 5, 768)    0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 8, 5, 128)    98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 8, 5, 800)    0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 8, 5, 800)    3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 8, 5, 800)    0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 8, 5, 128)    102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 8, 5, 832)    0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 8, 5, 832)    3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 8, 5, 832)    0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 8, 5, 128)    106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 8, 5, 864)    0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 8, 5, 864)    3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 8, 5, 864)    0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 8, 5, 128)    110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 8, 5, 896)    0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 8, 5, 896)    3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 8, 5, 896)    0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 8, 5, 128)    114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 8, 5, 928)    0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 8, 5, 928)    3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 8, 5, 928)    0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 8, 5, 128)    118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 8, 5, 960)    0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 8, 5, 960)    3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 8, 5, 960)    0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 8, 5, 128)    122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 8, 5, 992)    0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 8, 5, 992)    3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 8, 5, 992)    0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 8, 5, 128)    126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 8, 5, 1024)   0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 8, 5, 1024)   4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 8, 5, 1024)   0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 8, 5, 512)    524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 4, 2, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 4, 2, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 4, 2, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 4, 2, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 4, 2, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 4, 2, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 4, 2, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 4, 2, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 4, 2, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 4, 2, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 4, 2, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 4, 2, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 4, 2, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 4, 2, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 4, 2, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 4, 2, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 4, 2, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 4, 2, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 4, 2, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 4, 2, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 4, 2, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 4, 2, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 4, 2, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 4, 2, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 4, 2, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 4, 2, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 4, 2, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 4, 2, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 4, 2, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 4, 2, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 4, 2, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 4, 2, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 4, 2, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 4, 2, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 4, 2, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 4, 2, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 4, 2, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 4, 2, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 4, 2, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 4, 2, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 4, 2, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 4, 2, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 4, 2, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 4, 2, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 4, 2, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 4, 2, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 4, 2, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 4, 2, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 4, 2, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 4, 2, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 4, 2, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 4, 2, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 4, 2, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 4, 2, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 4, 2, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 4, 2, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 4, 2, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 4, 2, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 4, 2, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 4, 2, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 4, 2, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 4, 2, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 4, 2, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 4, 2, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 4, 2, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 4, 2, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 4, 2, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 4, 2, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 4, 2, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 4, 2, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 4, 2, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 4, 2, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 4, 2, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 4, 2, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 4, 2, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 4, 2, 1024)   0           bn[0][0]                         \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,037,504\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq20icnA-JB0",
        "colab_type": "code",
        "outputId": "b15f80d9-7432-47b2-930b-5607cb23e134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "train_datagen_denseNet = ImageDataGenerator(rotation_range=20,\n",
        "                               width_shift_range=0.2,\n",
        "                               height_shift_range=0.2,\n",
        "                               shear_range=0.2,\n",
        "                               zoom_range=0.2,\n",
        "                               horizontal_flip=True,\n",
        "                               rescale=1./255,\n",
        "                               fill_mode='nearest')\n",
        "\n",
        "validation_datagen_denseNet = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen_denseNet = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator_denseNet = train_datagen_denseNet.flow_from_directory(Train_dir,\n",
        "                                                    target_size = (140, 90),\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    shuffle=True\n",
        "                                                    )\n",
        "\n",
        "validation_genrator_denseNet = validation_datagen_denseNet.flow_from_directory(Valid_dir, \n",
        "                                                   target_size=(140, 90),\n",
        "                                                   batch_size = 181,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=True)\n",
        " \n",
        "test_generator_denseNet = test_datagen_denseNet.flow_from_directory(Test_dir, \n",
        "                                                  target_size = (140, 90),\n",
        "                                                  batch_size = 171,\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 788 images belonging to 6 classes.\n",
            "Found 181 images belonging to 6 classes.\n",
            "Found 171 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZonpZu_-Wu4",
        "colab_type": "code",
        "outputId": "af554a86-cb19-405c-bdbd-6b51a388be8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "K.clear_session()\n",
        "denseNet_model = models.Sequential()\n",
        "denseNet_model.add(densenet)\n",
        "denseNet_model.add(layers.Flatten())\n",
        "denseNet_model.add(layers.Dense(256, activation='relu'))\n",
        "denseNet_model.add(layers.Dense(6, activation='sigmoid'))\n",
        "\n",
        "densenet.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 140, 90, 3)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 146, 96, 3)   0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 70, 45, 64)   9408        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 70, 45, 64)   256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 70, 45, 64)   0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 72, 47, 64)   0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 35, 23, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 35, 23, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 35, 23, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 35, 23, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 35, 23, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 35, 23, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 35, 23, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 35, 23, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 35, 23, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 35, 23, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 35, 23, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 35, 23, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 35, 23, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 35, 23, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 35, 23, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 35, 23, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 35, 23, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 35, 23, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 35, 23, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 35, 23, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 35, 23, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 35, 23, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 35, 23, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 35, 23, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 35, 23, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 35, 23, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 35, 23, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 35, 23, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 35, 23, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 35, 23, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 35, 23, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 35, 23, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 35, 23, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 17, 11, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 17, 11, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 17, 11, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 17, 11, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 17, 11, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 17, 11, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 17, 11, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 17, 11, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 17, 11, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 17, 11, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 17, 11, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 17, 11, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 17, 11, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 17, 11, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 17, 11, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 17, 11, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 17, 11, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 17, 11, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 17, 11, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 17, 11, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 17, 11, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 17, 11, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 17, 11, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 17, 11, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 17, 11, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 17, 11, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 17, 11, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 17, 11, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 17, 11, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 17, 11, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 17, 11, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 17, 11, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 17, 11, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 17, 11, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 17, 11, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 17, 11, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 17, 11, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 17, 11, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 17, 11, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 17, 11, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 17, 11, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 17, 11, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 17, 11, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 17, 11, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 17, 11, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 17, 11, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 17, 11, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 17, 11, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 17, 11, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 17, 11, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 17, 11, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 17, 11, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 17, 11, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 17, 11, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 17, 11, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 17, 11, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 17, 11, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 17, 11, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 17, 11, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 17, 11, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 17, 11, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 8, 5, 256)    0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 8, 5, 256)    1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 8, 5, 256)    0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 8, 5, 128)    32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 8, 5, 128)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 8, 5, 288)    0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 8, 5, 288)    1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 8, 5, 288)    0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 8, 5, 128)    36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 8, 5, 128)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 8, 5, 320)    0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 8, 5, 320)    1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 8, 5, 320)    0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 8, 5, 128)    40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 8, 5, 128)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 8, 5, 352)    0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 8, 5, 352)    1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 8, 5, 352)    0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 8, 5, 128)    45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 8, 5, 128)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 8, 5, 384)    0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 8, 5, 384)    1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 8, 5, 384)    0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 8, 5, 128)    49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 8, 5, 128)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 8, 5, 416)    0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 8, 5, 416)    1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 8, 5, 416)    0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 8, 5, 128)    53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 8, 5, 128)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 8, 5, 448)    0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 8, 5, 448)    1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 8, 5, 448)    0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 8, 5, 128)    57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 8, 5, 128)    0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 8, 5, 480)    0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 8, 5, 480)    1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 8, 5, 480)    0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 8, 5, 128)    61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 8, 5, 128)    0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 8, 5, 512)    0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 8, 5, 512)    2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 8, 5, 512)    0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 8, 5, 128)    65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 8, 5, 128)    0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 8, 5, 544)    0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 8, 5, 544)    2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 8, 5, 544)    0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 8, 5, 128)    69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 8, 5, 576)    0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 8, 5, 576)    2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 8, 5, 576)    0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 8, 5, 128)    73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 8, 5, 608)    0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 8, 5, 608)    2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 8, 5, 608)    0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 8, 5, 128)    77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 8, 5, 640)    0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 8, 5, 640)    2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 8, 5, 640)    0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 8, 5, 128)    81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 8, 5, 672)    0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 8, 5, 672)    2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 8, 5, 672)    0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 8, 5, 128)    86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 8, 5, 704)    0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 8, 5, 704)    2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 8, 5, 704)    0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 8, 5, 128)    90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 8, 5, 736)    0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 8, 5, 736)    2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 8, 5, 736)    0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 8, 5, 128)    94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 8, 5, 768)    0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 8, 5, 768)    3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 8, 5, 768)    0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 8, 5, 128)    98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 8, 5, 800)    0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 8, 5, 800)    3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 8, 5, 800)    0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 8, 5, 128)    102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 8, 5, 832)    0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 8, 5, 832)    3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 8, 5, 832)    0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 8, 5, 128)    106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 8, 5, 864)    0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 8, 5, 864)    3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 8, 5, 864)    0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 8, 5, 128)    110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 8, 5, 896)    0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 8, 5, 896)    3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 8, 5, 896)    0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 8, 5, 128)    114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 8, 5, 928)    0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 8, 5, 928)    3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 8, 5, 928)    0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 8, 5, 128)    118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 8, 5, 960)    0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 8, 5, 960)    3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 8, 5, 960)    0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 8, 5, 128)    122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 8, 5, 992)    0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 8, 5, 992)    3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 8, 5, 992)    0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 8, 5, 128)    126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 8, 5, 1024)   0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 8, 5, 1024)   4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 8, 5, 1024)   0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 8, 5, 512)    524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 4, 2, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 4, 2, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 4, 2, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 4, 2, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 4, 2, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 4, 2, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 4, 2, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 4, 2, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 4, 2, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 4, 2, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 4, 2, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 4, 2, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 4, 2, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 4, 2, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 4, 2, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 4, 2, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 4, 2, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 4, 2, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 4, 2, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 4, 2, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 4, 2, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 4, 2, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 4, 2, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 4, 2, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 4, 2, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 4, 2, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 4, 2, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 4, 2, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 4, 2, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 4, 2, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 4, 2, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 4, 2, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 4, 2, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 4, 2, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 4, 2, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 4, 2, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 4, 2, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 4, 2, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 4, 2, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 4, 2, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 4, 2, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 4, 2, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 4, 2, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 4, 2, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 4, 2, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 4, 2, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 4, 2, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 4, 2, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 4, 2, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 4, 2, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 4, 2, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 4, 2, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 4, 2, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 4, 2, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 4, 2, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 4, 2, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 4, 2, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 4, 2, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 4, 2, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 4, 2, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 4, 2, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 4, 2, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 4, 2, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 4, 2, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 4, 2, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 4, 2, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 4, 2, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 4, 2, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 4, 2, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 4, 2, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 4, 2, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 4, 2, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 4, 2, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 4, 2, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 4, 2, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 4, 2, 1024)   0           bn[0][0]                         \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,037,504\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1bPVpeF-ga5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_dense_1 = ModelCheckpoint(filepath = 'my_best_model.hdf1', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "callback_dense_2 = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpDdWdGv-n42",
        "colab_type": "code",
        "outputId": "ccb3303e-4b81-4ce4-bc53-17442a55c9e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "denseNet_model.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_densenet = denseNet_model.fit_generator(train_generator_denseNet, \n",
        "                                    steps_per_epoch=100,\n",
        "                                    epochs=100,\n",
        "                                    callbacks=[callback_dense_1, callback_dense_2],\n",
        "                                    validation_data=validation_genrator_denseNet,\n",
        "                                    validation_steps=valid_images.shape[0] / 10\n",
        "                                  )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2565 - accuracy: 0.7627\n",
            "Epoch 00001: val_loss improved from inf to 0.09222, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 24s 239ms/step - loss: 0.2565 - accuracy: 0.7627 - val_loss: 0.0922 - val_accuracy: 0.9061\n",
            "Epoch 2/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0870 - accuracy: 0.9167\n",
            "Epoch 00002: val_loss did not improve from 0.09222\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0863 - accuracy: 0.9170 - val_loss: 0.0966 - val_accuracy: 0.9061\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9327\n",
            "Epoch 00003: val_loss did not improve from 0.09222\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0738 - accuracy: 0.9327 - val_loss: 0.0976 - val_accuracy: 0.8950\n",
            "Epoch 4/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 0.9397\n",
            "Epoch 00004: val_loss did not improve from 0.09222\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0679 - accuracy: 0.9394 - val_loss: 0.0973 - val_accuracy: 0.8950\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9494\n",
            "Epoch 00005: val_loss improved from 0.09222 to 0.09123, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.0533 - accuracy: 0.9494 - val_loss: 0.0912 - val_accuracy: 0.9171\n",
            "Epoch 6/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9514\n",
            "Epoch 00006: val_loss did not improve from 0.09123\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0540 - accuracy: 0.9511 - val_loss: 0.1051 - val_accuracy: 0.8895\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9626\n",
            "Epoch 00007: val_loss improved from 0.09123 to 0.08024, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.0445 - accuracy: 0.9626 - val_loss: 0.0802 - val_accuracy: 0.9337\n",
            "Epoch 8/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9657\n",
            "Epoch 00008: val_loss did not improve from 0.08024\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0443 - accuracy: 0.9649 - val_loss: 0.0813 - val_accuracy: 0.9282\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9686\n",
            "Epoch 00009: val_loss did not improve from 0.08024\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0367 - accuracy: 0.9686 - val_loss: 0.0889 - val_accuracy: 0.9282\n",
            "Epoch 10/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9668\n",
            "Epoch 00010: val_loss improved from 0.08024 to 0.06310, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0355 - accuracy: 0.9669 - val_loss: 0.0631 - val_accuracy: 0.9392\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9722\n",
            "Epoch 00011: val_loss did not improve from 0.06310\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0303 - accuracy: 0.9722 - val_loss: 0.0691 - val_accuracy: 0.9227\n",
            "Epoch 12/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9709\n",
            "Epoch 00012: val_loss did not improve from 0.06310\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0347 - accuracy: 0.9710 - val_loss: 0.0704 - val_accuracy: 0.9337\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9701\n",
            "Epoch 00013: val_loss did not improve from 0.06310\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0342 - accuracy: 0.9701 - val_loss: 0.0763 - val_accuracy: 0.9227\n",
            "Epoch 14/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0309 - accuracy: 0.9698\n",
            "Epoch 00014: val_loss improved from 0.06310 to 0.06013, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.0317 - accuracy: 0.9695 - val_loss: 0.0601 - val_accuracy: 0.9448\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9691\n",
            "Epoch 00015: val_loss did not improve from 0.06013\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0318 - accuracy: 0.9691 - val_loss: 0.0741 - val_accuracy: 0.9171\n",
            "Epoch 16/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9760\n",
            "Epoch 00016: val_loss improved from 0.06013 to 0.05832, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.0277 - accuracy: 0.9761 - val_loss: 0.0583 - val_accuracy: 0.9282\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9772\n",
            "Epoch 00017: val_loss did not improve from 0.05832\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.0236 - accuracy: 0.9772 - val_loss: 0.0647 - val_accuracy: 0.9337\n",
            "Epoch 18/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9775\n",
            "Epoch 00018: val_loss improved from 0.05832 to 0.03924, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.0253 - accuracy: 0.9776 - val_loss: 0.0392 - val_accuracy: 0.9724\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9818\n",
            "Epoch 00019: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0227 - accuracy: 0.9818 - val_loss: 0.0710 - val_accuracy: 0.9227\n",
            "Epoch 20/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9734\n",
            "Epoch 00020: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0268 - accuracy: 0.9735 - val_loss: 0.0659 - val_accuracy: 0.9282\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9732\n",
            "Epoch 00021: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0257 - accuracy: 0.9732 - val_loss: 0.0722 - val_accuracy: 0.9558\n",
            "Epoch 22/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9811\n",
            "Epoch 00022: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0187 - accuracy: 0.9812 - val_loss: 0.0552 - val_accuracy: 0.9448\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9813\n",
            "Epoch 00023: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.0195 - accuracy: 0.9813 - val_loss: 0.0674 - val_accuracy: 0.9392\n",
            "Epoch 24/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9755\n",
            "Epoch 00024: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0245 - accuracy: 0.9756 - val_loss: 0.0963 - val_accuracy: 0.8950\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9843\n",
            "Epoch 00025: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0158 - accuracy: 0.9843 - val_loss: 0.0626 - val_accuracy: 0.9503\n",
            "Epoch 26/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9765\n",
            "Epoch 00026: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0258 - accuracy: 0.9761 - val_loss: 0.0857 - val_accuracy: 0.9337\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9793\n",
            "Epoch 00027: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0239 - accuracy: 0.9793 - val_loss: 0.0565 - val_accuracy: 0.9448\n",
            "Epoch 28/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9755\n",
            "Epoch 00028: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0253 - accuracy: 0.9756 - val_loss: 0.0734 - val_accuracy: 0.9448\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9782\n",
            "Epoch 00029: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.0202 - accuracy: 0.9782 - val_loss: 0.0543 - val_accuracy: 0.9503\n",
            "Epoch 30/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9775\n",
            "Epoch 00030: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0234 - accuracy: 0.9776 - val_loss: 0.0748 - val_accuracy: 0.9392\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9742\n",
            "Epoch 00031: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.0279 - accuracy: 0.9742 - val_loss: 0.0630 - val_accuracy: 0.9392\n",
            "Epoch 32/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9816\n",
            "Epoch 00032: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0179 - accuracy: 0.9817 - val_loss: 0.0477 - val_accuracy: 0.9558\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9848\n",
            "Epoch 00033: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.0173 - accuracy: 0.9848 - val_loss: 0.0770 - val_accuracy: 0.9282\n",
            "Epoch 34/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9796\n",
            "Epoch 00034: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.0219 - accuracy: 0.9796 - val_loss: 0.0571 - val_accuracy: 0.9448\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9848\n",
            "Epoch 00035: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0174 - accuracy: 0.9848 - val_loss: 0.0773 - val_accuracy: 0.9171\n",
            "Epoch 36/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9790\n",
            "Epoch 00036: val_loss did not improve from 0.03924\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0226 - accuracy: 0.9791 - val_loss: 0.0703 - val_accuracy: 0.9448\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9858\n",
            "Epoch 00037: val_loss improved from 0.03924 to 0.03771, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.0172 - accuracy: 0.9858 - val_loss: 0.0377 - val_accuracy: 0.9613\n",
            "Epoch 38/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9857\n",
            "Epoch 00038: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0141 - accuracy: 0.9857 - val_loss: 0.0846 - val_accuracy: 0.9392\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9838\n",
            "Epoch 00039: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0176 - accuracy: 0.9838 - val_loss: 0.0631 - val_accuracy: 0.9503\n",
            "Epoch 40/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9862\n",
            "Epoch 00040: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.0163 - accuracy: 0.9863 - val_loss: 0.0752 - val_accuracy: 0.9171\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9782\n",
            "Epoch 00041: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0202 - accuracy: 0.9782 - val_loss: 0.0732 - val_accuracy: 0.9448\n",
            "Epoch 42/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9826\n",
            "Epoch 00042: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0192 - accuracy: 0.9827 - val_loss: 0.0713 - val_accuracy: 0.9227\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9843\n",
            "Epoch 00043: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0180 - accuracy: 0.9843 - val_loss: 0.0681 - val_accuracy: 0.9337\n",
            "Epoch 44/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9842\n",
            "Epoch 00044: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0219 - accuracy: 0.9842 - val_loss: 0.0853 - val_accuracy: 0.9392\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9848\n",
            "Epoch 00045: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0153 - accuracy: 0.9848 - val_loss: 0.0593 - val_accuracy: 0.9448\n",
            "Epoch 46/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9821\n",
            "Epoch 00046: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0191 - accuracy: 0.9822 - val_loss: 0.0439 - val_accuracy: 0.9448\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9853\n",
            "Epoch 00047: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0159 - accuracy: 0.9853 - val_loss: 0.0781 - val_accuracy: 0.9337\n",
            "Epoch 48/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9852\n",
            "Epoch 00048: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0162 - accuracy: 0.9852 - val_loss: 0.0837 - val_accuracy: 0.9171\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9742\n",
            "Epoch 00049: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0235 - accuracy: 0.9742 - val_loss: 0.0688 - val_accuracy: 0.9282\n",
            "Epoch 50/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9872\n",
            "Epoch 00050: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.0169 - accuracy: 0.9873 - val_loss: 0.0897 - val_accuracy: 0.9227\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9894\n",
            "Epoch 00051: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.0114 - accuracy: 0.9894 - val_loss: 0.0802 - val_accuracy: 0.9337\n",
            "Epoch 52/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9898\n",
            "Epoch 00052: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0123 - accuracy: 0.9898 - val_loss: 0.1001 - val_accuracy: 0.9116\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9914\n",
            "Epoch 00053: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0115 - accuracy: 0.9914 - val_loss: 0.0820 - val_accuracy: 0.9337\n",
            "Epoch 54/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9928\n",
            "Epoch 00054: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0090 - accuracy: 0.9929 - val_loss: 0.0654 - val_accuracy: 0.9392\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9919\n",
            "Epoch 00055: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0077 - accuracy: 0.9919 - val_loss: 0.0894 - val_accuracy: 0.9337\n",
            "Epoch 56/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9831\n",
            "Epoch 00056: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0175 - accuracy: 0.9832 - val_loss: 0.0885 - val_accuracy: 0.9392\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9863\n",
            "Epoch 00057: val_loss did not improve from 0.03771\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0156 - accuracy: 0.9863 - val_loss: 0.0691 - val_accuracy: 0.9448\n",
            "Epoch 00057: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmbGA1bx-y_q",
        "colab_type": "code",
        "outputId": "d5f1965c-343e-4b11-91d9-0d115cece297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history_densenet.history['accuracy'])\n",
        "plt.plot(history_densenet.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_densenet.history['loss'])\n",
        "plt.plot(history_densenet.history['val_loss'])\n",
        "plt.title('Model Loss') \n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'lower left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tudBrcR-5py",
        "colab_type": "code",
        "outputId": "f777b135-d847-4705-c353-487dc10753d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "validation_loss_dense, validation_acc_dense = denseNet_model.evaluate_generator(validation_genrator_denseNet, steps=10)\n",
        "print( 'validation_acc:', validation_acc_dense)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation_acc: 0.9447513818740845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB3BKIfA_A-I",
        "colab_type": "code",
        "outputId": "f29e09fb-8924-436c-ef55-8a9f1c65c7f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_loss_dense, test_acc_dense = denseNet_model.evaluate_generator(test_generator_denseNet, steps=30)\n",
        "print('test_acc:', test_acc_dense)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.9649122953414917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmLnHUzPRNlI",
        "colab_type": "text"
      },
      "source": [
        "### **DenseNet with Regularizer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgBDJtuqRRXe",
        "colab_type": "code",
        "outputId": "2c4982b2-dcd9-48e9-d586-890b26313841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "train_datagen_denseNet_1 = ImageDataGenerator(rotation_range=20,\n",
        "                               width_shift_range=0.2,\n",
        "                               height_shift_range=0.2,\n",
        "                               shear_range=0.2,\n",
        "                               zoom_range=0.2,\n",
        "                               horizontal_flip=True,\n",
        "                               rescale=1./255,\n",
        "                               fill_mode='nearest')\n",
        "\n",
        "validation_datagen_denseNet_1 = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen_denseNet_1 = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator_denseNet_1 = train_datagen_denseNet_1.flow_from_directory(Train_dir,\n",
        "                                                    target_size = (140, 90),\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    shuffle=True\n",
        "                                                    )\n",
        "\n",
        "validation_genrator_denseNet_1 = validation_datagen_denseNet_1.flow_from_directory(Valid_dir, \n",
        "                                                   target_size=(140, 90),\n",
        "                                                   batch_size = 181,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=True)\n",
        " \n",
        "test_generator_denseNet_1 = test_datagen_denseNet_1.flow_from_directory(Test_dir, \n",
        "                                                  target_size = (140, 90),\n",
        "                                                  batch_size = 171,\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 788 images belonging to 6 classes.\n",
            "Found 181 images belonging to 6 classes.\n",
            "Found 171 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZEC2yvYTDCF",
        "colab_type": "code",
        "outputId": "f674c1b5-349a-4504-b627-17990874e0e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "K.clear_session()\n",
        "denseNet_model_1 = models.Sequential()\n",
        "denseNet_model_1.add(densenet)\n",
        "denseNet_model_1.add(layers.Flatten())\n",
        "denseNet_model_1.add(layers.Dense(256, activation='relu'))\n",
        "denseNet_model_1.add(layers.Dropout(0.5))\n",
        "denseNet_model_1.add(layers.Dense(6, activation='sigmoid'))\n",
        "\n",
        "densenet.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 140, 90, 3)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 146, 96, 3)   0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 70, 45, 64)   9408        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 70, 45, 64)   256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 70, 45, 64)   0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 72, 47, 64)   0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 35, 23, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 35, 23, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 35, 23, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 35, 23, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 35, 23, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 35, 23, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 35, 23, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 35, 23, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 35, 23, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 35, 23, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 35, 23, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 35, 23, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 35, 23, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 35, 23, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 35, 23, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 35, 23, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 35, 23, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 35, 23, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 35, 23, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 35, 23, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 35, 23, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 35, 23, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 35, 23, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 35, 23, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 35, 23, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 35, 23, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 35, 23, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 35, 23, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 35, 23, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 35, 23, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 35, 23, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 35, 23, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 35, 23, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 17, 11, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 17, 11, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 17, 11, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 17, 11, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 17, 11, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 17, 11, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 17, 11, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 17, 11, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 17, 11, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 17, 11, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 17, 11, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 17, 11, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 17, 11, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 17, 11, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 17, 11, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 17, 11, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 17, 11, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 17, 11, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 17, 11, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 17, 11, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 17, 11, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 17, 11, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 17, 11, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 17, 11, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 17, 11, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 17, 11, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 17, 11, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 17, 11, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 17, 11, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 17, 11, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 17, 11, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 17, 11, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 17, 11, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 17, 11, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 17, 11, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 17, 11, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 17, 11, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 17, 11, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 17, 11, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 17, 11, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 17, 11, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 17, 11, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 17, 11, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 17, 11, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 17, 11, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 17, 11, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 17, 11, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 17, 11, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 17, 11, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 17, 11, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 17, 11, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 17, 11, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 17, 11, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 17, 11, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 17, 11, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 17, 11, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 17, 11, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 17, 11, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 17, 11, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 17, 11, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 17, 11, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 8, 5, 256)    0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 8, 5, 256)    1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 8, 5, 256)    0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 8, 5, 128)    32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 8, 5, 128)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 8, 5, 288)    0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 8, 5, 288)    1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 8, 5, 288)    0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 8, 5, 128)    36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 8, 5, 128)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 8, 5, 320)    0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 8, 5, 320)    1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 8, 5, 320)    0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 8, 5, 128)    40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 8, 5, 128)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 8, 5, 352)    0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 8, 5, 352)    1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 8, 5, 352)    0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 8, 5, 128)    45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 8, 5, 128)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 8, 5, 384)    0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 8, 5, 384)    1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 8, 5, 384)    0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 8, 5, 128)    49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 8, 5, 128)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 8, 5, 416)    0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 8, 5, 416)    1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 8, 5, 416)    0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 8, 5, 128)    53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 8, 5, 128)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 8, 5, 448)    0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 8, 5, 448)    1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 8, 5, 448)    0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 8, 5, 128)    57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 8, 5, 128)    0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 8, 5, 480)    0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 8, 5, 480)    1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 8, 5, 480)    0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 8, 5, 128)    61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 8, 5, 128)    0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 8, 5, 512)    0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 8, 5, 512)    2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 8, 5, 512)    0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 8, 5, 128)    65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 8, 5, 128)    0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 8, 5, 544)    0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 8, 5, 544)    2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 8, 5, 544)    0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 8, 5, 128)    69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 8, 5, 576)    0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 8, 5, 576)    2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 8, 5, 576)    0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 8, 5, 128)    73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 8, 5, 608)    0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 8, 5, 608)    2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 8, 5, 608)    0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 8, 5, 128)    77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 8, 5, 640)    0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 8, 5, 640)    2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 8, 5, 640)    0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 8, 5, 128)    81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 8, 5, 672)    0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 8, 5, 672)    2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 8, 5, 672)    0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 8, 5, 128)    86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 8, 5, 704)    0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 8, 5, 704)    2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 8, 5, 704)    0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 8, 5, 128)    90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 8, 5, 736)    0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 8, 5, 736)    2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 8, 5, 736)    0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 8, 5, 128)    94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 8, 5, 768)    0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 8, 5, 768)    3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 8, 5, 768)    0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 8, 5, 128)    98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 8, 5, 800)    0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 8, 5, 800)    3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 8, 5, 800)    0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 8, 5, 128)    102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 8, 5, 832)    0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 8, 5, 832)    3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 8, 5, 832)    0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 8, 5, 128)    106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 8, 5, 864)    0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 8, 5, 864)    3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 8, 5, 864)    0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 8, 5, 128)    110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 8, 5, 896)    0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 8, 5, 896)    3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 8, 5, 896)    0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 8, 5, 128)    114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 8, 5, 928)    0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 8, 5, 928)    3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 8, 5, 928)    0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 8, 5, 128)    118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 8, 5, 960)    0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 8, 5, 960)    3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 8, 5, 960)    0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 8, 5, 128)    122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 8, 5, 992)    0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 8, 5, 992)    3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 8, 5, 992)    0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 8, 5, 128)    126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 8, 5, 1024)   0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 8, 5, 1024)   4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 8, 5, 1024)   0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 8, 5, 512)    524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 4, 2, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 4, 2, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 4, 2, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 4, 2, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 4, 2, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 4, 2, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 4, 2, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 4, 2, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 4, 2, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 4, 2, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 4, 2, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 4, 2, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 4, 2, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 4, 2, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 4, 2, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 4, 2, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 4, 2, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 4, 2, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 4, 2, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 4, 2, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 4, 2, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 4, 2, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 4, 2, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 4, 2, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 4, 2, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 4, 2, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 4, 2, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 4, 2, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 4, 2, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 4, 2, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 4, 2, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 4, 2, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 4, 2, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 4, 2, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 4, 2, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 4, 2, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 4, 2, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 4, 2, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 4, 2, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 4, 2, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 4, 2, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 4, 2, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 4, 2, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 4, 2, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 4, 2, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 4, 2, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 4, 2, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 4, 2, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 4, 2, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 4, 2, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 4, 2, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 4, 2, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 4, 2, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 4, 2, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 4, 2, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 4, 2, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 4, 2, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 4, 2, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 4, 2, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 4, 2, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 4, 2, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 4, 2, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 4, 2, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 4, 2, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 4, 2, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 4, 2, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 4, 2, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 4, 2, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 4, 2, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 4, 2, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 4, 2, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 4, 2, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 4, 2, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 4, 2, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 4, 2, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 4, 2, 1024)   0           bn[0][0]                         \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,037,504\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGp36swYV8l4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_dense_3 = ModelCheckpoint(filepath = 'my_best_model.hdf1', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "callback_dense_4 = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dId1eyEFWFUb",
        "colab_type": "code",
        "outputId": "5f9f0d12-d77d-4cc4-922b-f35d183ed7ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "denseNet_model_1.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_densenet_1 = denseNet_model_1.fit_generator(train_generator_denseNet, \n",
        "                                    steps_per_epoch=100,\n",
        "                                    epochs=100,\n",
        "                                    callbacks=[callback_dense_3, callback_dense_4],\n",
        "                                    validation_data=validation_genrator_denseNet,\n",
        "                                    validation_steps=valid_images.shape[0] / 10\n",
        "                                  )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3436 - accuracy: 0.6950\n",
            "Epoch 00001: val_loss improved from inf to 0.10787, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.3436 - accuracy: 0.6950 - val_loss: 0.1079 - val_accuracy: 0.8785\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.8472\n",
            "Epoch 00002: val_loss improved from 0.10787 to 0.09794, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 19s 187ms/step - loss: 0.1505 - accuracy: 0.8472 - val_loss: 0.0979 - val_accuracy: 0.8895\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.8824\n",
            "Epoch 00003: val_loss improved from 0.09794 to 0.07758, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.1205 - accuracy: 0.8824 - val_loss: 0.0776 - val_accuracy: 0.9171\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.8937\n",
            "Epoch 00004: val_loss improved from 0.07758 to 0.07126, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.1091 - accuracy: 0.8937 - val_loss: 0.0713 - val_accuracy: 0.9282\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.9058\n",
            "Epoch 00005: val_loss improved from 0.07126 to 0.06144, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.0930 - accuracy: 0.9058 - val_loss: 0.0614 - val_accuracy: 0.9227\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9089\n",
            "Epoch 00006: val_loss improved from 0.06144 to 0.05897, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.0892 - accuracy: 0.9089 - val_loss: 0.0590 - val_accuracy: 0.9282\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9155\n",
            "Epoch 00007: val_loss did not improve from 0.05897\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0828 - accuracy: 0.9155 - val_loss: 0.0685 - val_accuracy: 0.9227\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9251\n",
            "Epoch 00008: val_loss did not improve from 0.05897\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0761 - accuracy: 0.9251 - val_loss: 0.0653 - val_accuracy: 0.9171\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9282\n",
            "Epoch 00009: val_loss improved from 0.05897 to 0.05689, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0769 - accuracy: 0.9282 - val_loss: 0.0569 - val_accuracy: 0.9392\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9297\n",
            "Epoch 00010: val_loss did not improve from 0.05689\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.0715 - accuracy: 0.9297 - val_loss: 0.0708 - val_accuracy: 0.9171\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9262\n",
            "Epoch 00011: val_loss improved from 0.05689 to 0.05609, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0709 - accuracy: 0.9262 - val_loss: 0.0561 - val_accuracy: 0.9282\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9312\n",
            "Epoch 00012: val_loss did not improve from 0.05609\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.0717 - accuracy: 0.9312 - val_loss: 0.0699 - val_accuracy: 0.9337\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9323\n",
            "Epoch 00013: val_loss improved from 0.05609 to 0.05323, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.0667 - accuracy: 0.9323 - val_loss: 0.0532 - val_accuracy: 0.9392\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9347\n",
            "Epoch 00014: val_loss did not improve from 0.05323\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0611 - accuracy: 0.9347 - val_loss: 0.0709 - val_accuracy: 0.9227\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9297\n",
            "Epoch 00015: val_loss improved from 0.05323 to 0.05058, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 185ms/step - loss: 0.0681 - accuracy: 0.9297 - val_loss: 0.0506 - val_accuracy: 0.9392\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9372\n",
            "Epoch 00016: val_loss did not improve from 0.05058\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0592 - accuracy: 0.9372 - val_loss: 0.0833 - val_accuracy: 0.9171\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9425\n",
            "Epoch 00017: val_loss did not improve from 0.05058\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0656 - accuracy: 0.9425 - val_loss: 0.0638 - val_accuracy: 0.9282\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9378\n",
            "Epoch 00018: val_loss did not improve from 0.05058\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0617 - accuracy: 0.9378 - val_loss: 0.0550 - val_accuracy: 0.9337\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9389\n",
            "Epoch 00019: val_loss did not improve from 0.05058\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0545 - accuracy: 0.9389 - val_loss: 0.0596 - val_accuracy: 0.9337\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9337\n",
            "Epoch 00020: val_loss improved from 0.05058 to 0.05032, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 185ms/step - loss: 0.0660 - accuracy: 0.9337 - val_loss: 0.0503 - val_accuracy: 0.9392\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9374\n",
            "Epoch 00021: val_loss did not improve from 0.05032\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0593 - accuracy: 0.9374 - val_loss: 0.0602 - val_accuracy: 0.9337\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9479\n",
            "Epoch 00022: val_loss did not improve from 0.05032\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0484 - accuracy: 0.9479 - val_loss: 0.0516 - val_accuracy: 0.9392\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9491\n",
            "Epoch 00023: val_loss improved from 0.05032 to 0.04780, saving model to my_best_model.hdf1\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0544 - accuracy: 0.9491 - val_loss: 0.0478 - val_accuracy: 0.9503\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9453\n",
            "Epoch 00024: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.0499 - accuracy: 0.9453 - val_loss: 0.0574 - val_accuracy: 0.9448\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9537\n",
            "Epoch 00025: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0474 - accuracy: 0.9537 - val_loss: 0.0649 - val_accuracy: 0.9282\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9620\n",
            "Epoch 00026: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.0383 - accuracy: 0.9620 - val_loss: 0.0685 - val_accuracy: 0.9337\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9572\n",
            "Epoch 00027: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0465 - accuracy: 0.9572 - val_loss: 0.0757 - val_accuracy: 0.9282\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9474\n",
            "Epoch 00028: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0496 - accuracy: 0.9474 - val_loss: 0.0622 - val_accuracy: 0.9392\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9628\n",
            "Epoch 00029: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.0380 - accuracy: 0.9628 - val_loss: 0.0706 - val_accuracy: 0.9282\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9499\n",
            "Epoch 00030: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.0504 - accuracy: 0.9499 - val_loss: 0.0632 - val_accuracy: 0.9448\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9521\n",
            "Epoch 00031: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0485 - accuracy: 0.9521 - val_loss: 0.0619 - val_accuracy: 0.9392\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9362\n",
            "Epoch 00032: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0632 - accuracy: 0.9362 - val_loss: 0.0591 - val_accuracy: 0.9392\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9399\n",
            "Epoch 00033: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0569 - accuracy: 0.9399 - val_loss: 0.0665 - val_accuracy: 0.9227\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.9378\n",
            "Epoch 00034: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.0641 - accuracy: 0.9378 - val_loss: 0.0580 - val_accuracy: 0.9392\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9420\n",
            "Epoch 00035: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0577 - accuracy: 0.9420 - val_loss: 0.0565 - val_accuracy: 0.9227\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9524\n",
            "Epoch 00036: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.0453 - accuracy: 0.9524 - val_loss: 0.0560 - val_accuracy: 0.9392\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9435\n",
            "Epoch 00037: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0594 - accuracy: 0.9435 - val_loss: 0.0556 - val_accuracy: 0.9337\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9585\n",
            "Epoch 00038: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0397 - accuracy: 0.9585 - val_loss: 0.0633 - val_accuracy: 0.9282\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9567\n",
            "Epoch 00039: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0421 - accuracy: 0.9567 - val_loss: 0.0753 - val_accuracy: 0.9282\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9590\n",
            "Epoch 00040: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.0398 - accuracy: 0.9590 - val_loss: 0.0502 - val_accuracy: 0.9448\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9562\n",
            "Epoch 00041: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0451 - accuracy: 0.9562 - val_loss: 0.0619 - val_accuracy: 0.9392\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9519\n",
            "Epoch 00042: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.0469 - accuracy: 0.9519 - val_loss: 0.0615 - val_accuracy: 0.9392\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9526\n",
            "Epoch 00043: val_loss did not improve from 0.04780\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.0424 - accuracy: 0.9526 - val_loss: 0.0587 - val_accuracy: 0.9448\n",
            "Epoch 00043: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E67c7-NVWST2",
        "colab_type": "code",
        "outputId": "a5dbf4c7-d9ef-4493-ca6b-f63eb65933da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history_densenet_1.history['accuracy'])\n",
        "plt.plot(history_densenet_1.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_densenet_1.history['loss'])\n",
        "plt.plot(history_densenet_1.history['val_loss'])\n",
        "plt.title('Model Loss') \n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'lower left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPmmxBIPWWrK",
        "colab_type": "code",
        "outputId": "6ff5c20d-1b82-4b94-b0ce-84f1ad9b415d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "validation_loss_dense_1, validation_acc_dense_1 = denseNet_model_1.evaluate_generator(validation_genrator_denseNet_1, steps=10)\n",
        "print( 'validation_acc:', validation_acc_dense_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation_acc: 0.9447513818740845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBpMl8aqWixl",
        "colab_type": "code",
        "outputId": "bfc67ded-d0d0-4bed-98b0-8cff100fcb6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_loss_dense_1, test_acc_dense_1 = denseNet_model_1.evaluate_generator(test_generator_denseNet_1, steps=30)\n",
        "print('test_acc:', test_acc_dense_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.9356725215911865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQVFm7kz0NHz",
        "colab_type": "text"
      },
      "source": [
        "##**Fine Tuning**\n",
        "\n",
        "### VGG16 with the Dropout Layer, has better perfomance on Validation Accuracy by 0.04. \n",
        "\n",
        "### ResNet 50 without Dropout Layer, has better performance on Validation Accuracy\n",
        "\n",
        "### Inception V3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sm8sJkD0Mm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_fine_tuned = VGG16(weights='imagenet', include_top = False, input_shape=(140,90,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TK57aV58zyK",
        "colab_type": "code",
        "outputId": "9145e3bc-422c-4a8a-deba-d8392bf7b9bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        }
      },
      "source": [
        "vgg16_fine_tuned.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 140, 90, 3)]      0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 140, 90, 64)       1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 140, 90, 64)       36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 70, 45, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 70, 45, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 70, 45, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 35, 22, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 35, 22, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 35, 22, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 35, 22, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 17, 11, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 17, 11, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 17, 11, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 17, 11, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 5, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 2, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2_Hucg78nyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_fine_tuned.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in vgg16_fine_tuned.layers:\n",
        "  if layer.name == 'block5_conv1':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FybRLzw9-2A",
        "colab_type": "code",
        "outputId": "67314a0f-8cf7-48a3-cac5-addad7956ab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "train_datagen_VGG16_ft = ImageDataGenerator(rotation_range=40,\n",
        "                               width_shift_range=0.4,\n",
        "                               height_shift_range=0.4,\n",
        "                               shear_range=0.4,\n",
        "                               zoom_range=0.4,\n",
        "                               horizontal_flip=True,\n",
        "                               rescale=1./255,\n",
        "                               fill_mode='nearest')\n",
        "\n",
        "validation_datagen_VGG16_ft = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen_VGG16_ft = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator_VGG16_ft = train_datagen_VGG16_ft.flow_from_directory(Train_dir,\n",
        "                                                    target_size = (140, 90),\n",
        "                                                    batch_size = 50,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    shuffle=True\n",
        "                                                    )\n",
        "\n",
        "validation_genrator_VGG16_ft = validation_datagen_VGG16_ft.flow_from_directory(Valid_dir, \n",
        "                                                   target_size=(140, 90),\n",
        "                                                   batch_size = 181,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=True)\n",
        " \n",
        "test_generator_VGG16_ft = test_datagen_VGG16_ft.flow_from_directory(Test_dir, \n",
        "                                                  target_size = (140, 90),\n",
        "                                                  batch_size = 171 ,\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 788 images belonging to 6 classes.\n",
            "Found 181 images belonging to 6 classes.\n",
            "Found 171 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDuzX2bx9Rbd",
        "colab_type": "code",
        "outputId": "d99bf792-c138-48e2-b5cc-6b213f4122fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "K.clear_session()\n",
        "vgg16_fine_tuned_model = models.Sequential()\n",
        "vgg16_fine_tuned_model.add(vgg16_fine_tuned)\n",
        "vgg16_fine_tuned_model.add(layers.Flatten())\n",
        "vgg16_fine_tuned_model.add(layers.Dense(256, activation='relu'))\n",
        "vgg16_fine_tuned_model.add(layers.Dropout(0.5))\n",
        "vgg16_fine_tuned_model.add(layers.Dense(6, activation='sigmoid'))\n",
        "\n",
        "vgg16_fine_tuned_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 4, 2, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               1048832   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 1542      \n",
            "=================================================================\n",
            "Total params: 15,765,062\n",
            "Trainable params: 8,129,798\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUBl0MRa_XUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_M = ModelCheckpoint(filepath = 'my_best_model.hdf7', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "callback_N = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBOm_8yw_AYq",
        "colab_type": "code",
        "outputId": "03090e4c-e7eb-4e47-b745-f1c203ccacb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vgg16_fine_tuned_model.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_vgg16_fine_tuned = vgg16_fine_tuned_model.fit_generator(train_generator_VGG16_ft, \n",
        "                                    steps_per_epoch=100,\n",
        "                                    epochs=100,\n",
        "                                    callbacks=[callback_M, callback_N],\n",
        "                                    validation_data=validation_genrator_VGG16_ft,\n",
        "                                    validation_steps=valid_images.shape[0] / 10\n",
        "                                  )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3684 - accuracy: 0.4278\n",
            "Epoch 00001: val_loss improved from inf to 0.21209, saving model to my_best_model.hdf7\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 0.3684 - accuracy: 0.4278 - val_loss: 0.2121 - val_accuracy: 0.6961\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.6719\n",
            "Epoch 00002: val_loss improved from 0.21209 to 0.16890, saving model to my_best_model.hdf7\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 0.2213 - accuracy: 0.6719 - val_loss: 0.1689 - val_accuracy: 0.7514\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.7599\n",
            "Epoch 00003: val_loss improved from 0.16890 to 0.11859, saving model to my_best_model.hdf7\n",
            "100/100 [==============================] - 36s 363ms/step - loss: 0.1749 - accuracy: 0.7599 - val_loss: 0.1186 - val_accuracy: 0.7956\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.8297\n",
            "Epoch 00004: val_loss improved from 0.11859 to 0.11732, saving model to my_best_model.hdf7\n",
            "100/100 [==============================] - 37s 368ms/step - loss: 0.1374 - accuracy: 0.8297 - val_loss: 0.1173 - val_accuracy: 0.8674\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1257 - accuracy: 0.8504\n",
            "Epoch 00005: val_loss improved from 0.11732 to 0.06456, saving model to my_best_model.hdf7\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 0.1257 - accuracy: 0.8504 - val_loss: 0.0646 - val_accuracy: 0.9337\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.8770\n",
            "Epoch 00006: val_loss did not improve from 0.06456\n",
            "100/100 [==============================] - 35s 353ms/step - loss: 0.1041 - accuracy: 0.8770 - val_loss: 0.0650 - val_accuracy: 0.9227\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.8941\n",
            "Epoch 00007: val_loss improved from 0.06456 to 0.04107, saving model to my_best_model.hdf7\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 0.0939 - accuracy: 0.8941 - val_loss: 0.0411 - val_accuracy: 0.9613\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.8940\n",
            "Epoch 00008: val_loss did not improve from 0.04107\n",
            "100/100 [==============================] - 35s 355ms/step - loss: 0.0922 - accuracy: 0.8940 - val_loss: 0.0623 - val_accuracy: 0.9392\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9022\n",
            "Epoch 00009: val_loss did not improve from 0.04107\n",
            "100/100 [==============================] - 35s 353ms/step - loss: 0.0852 - accuracy: 0.9022 - val_loss: 0.0663 - val_accuracy: 0.9503\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9125\n",
            "Epoch 00010: val_loss did not improve from 0.04107\n",
            "100/100 [==============================] - 34s 337ms/step - loss: 0.0754 - accuracy: 0.9125 - val_loss: 0.0485 - val_accuracy: 0.9669\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9251\n",
            "Epoch 00011: val_loss did not improve from 0.04107\n",
            "100/100 [==============================] - 34s 342ms/step - loss: 0.0702 - accuracy: 0.9251 - val_loss: 0.0466 - val_accuracy: 0.9558\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9304\n",
            "Epoch 00012: val_loss did not improve from 0.04107\n",
            "100/100 [==============================] - 35s 347ms/step - loss: 0.0615 - accuracy: 0.9304 - val_loss: 0.0492 - val_accuracy: 0.9669\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 0.9247\n",
            "Epoch 00013: val_loss did not improve from 0.04107\n",
            "100/100 [==============================] - 35s 352ms/step - loss: 0.0662 - accuracy: 0.9247 - val_loss: 0.0510 - val_accuracy: 0.9669\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9359\n",
            "Epoch 00014: val_loss did not improve from 0.04107\n",
            "100/100 [==============================] - 34s 341ms/step - loss: 0.0612 - accuracy: 0.9359 - val_loss: 0.0637 - val_accuracy: 0.9669\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9274\n",
            "Epoch 00015: val_loss did not improve from 0.04107\n",
            "100/100 [==============================] - 34s 344ms/step - loss: 0.0631 - accuracy: 0.9274 - val_loss: 0.0870 - val_accuracy: 0.9337\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9390\n",
            "Epoch 00016: val_loss improved from 0.04107 to 0.03828, saving model to my_best_model.hdf7\n",
            "100/100 [==============================] - 34s 339ms/step - loss: 0.0581 - accuracy: 0.9390 - val_loss: 0.0383 - val_accuracy: 0.9613\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9347\n",
            "Epoch 00017: val_loss did not improve from 0.03828\n",
            "100/100 [==============================] - 34s 340ms/step - loss: 0.0565 - accuracy: 0.9347 - val_loss: 0.0814 - val_accuracy: 0.9613\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9456\n",
            "Epoch 00018: val_loss improved from 0.03828 to 0.03517, saving model to my_best_model.hdf7\n",
            "100/100 [==============================] - 34s 342ms/step - loss: 0.0464 - accuracy: 0.9456 - val_loss: 0.0352 - val_accuracy: 0.9613\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9359\n",
            "Epoch 00019: val_loss did not improve from 0.03517\n",
            "100/100 [==============================] - 33s 335ms/step - loss: 0.0580 - accuracy: 0.9359 - val_loss: 0.0560 - val_accuracy: 0.9613\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9457\n",
            "Epoch 00020: val_loss did not improve from 0.03517\n",
            "100/100 [==============================] - 34s 337ms/step - loss: 0.0513 - accuracy: 0.9457 - val_loss: 0.0700 - val_accuracy: 0.9669\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9493\n",
            "Epoch 00021: val_loss did not improve from 0.03517\n",
            "100/100 [==============================] - 34s 345ms/step - loss: 0.0478 - accuracy: 0.9493 - val_loss: 0.0589 - val_accuracy: 0.9558\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9456\n",
            "Epoch 00022: val_loss did not improve from 0.03517\n",
            "100/100 [==============================] - 35s 349ms/step - loss: 0.0475 - accuracy: 0.9456 - val_loss: 0.0579 - val_accuracy: 0.9448\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9503\n",
            "Epoch 00023: val_loss did not improve from 0.03517\n",
            "100/100 [==============================] - 34s 340ms/step - loss: 0.0460 - accuracy: 0.9503 - val_loss: 0.0719 - val_accuracy: 0.9558\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9512\n",
            "Epoch 00024: val_loss did not improve from 0.03517\n",
            "100/100 [==============================] - 34s 341ms/step - loss: 0.0426 - accuracy: 0.9512 - val_loss: 0.0729 - val_accuracy: 0.9613\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9507\n",
            "Epoch 00025: val_loss did not improve from 0.03517\n",
            "100/100 [==============================] - 34s 339ms/step - loss: 0.0486 - accuracy: 0.9507 - val_loss: 0.0611 - val_accuracy: 0.9724\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9478\n",
            "Epoch 00026: val_loss improved from 0.03517 to 0.03493, saving model to my_best_model.hdf7\n",
            "100/100 [==============================] - 34s 339ms/step - loss: 0.0467 - accuracy: 0.9478 - val_loss: 0.0349 - val_accuracy: 0.9669\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9493\n",
            "Epoch 00027: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 34s 345ms/step - loss: 0.0425 - accuracy: 0.9493 - val_loss: 0.0578 - val_accuracy: 0.9558\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9569\n",
            "Epoch 00028: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 34s 339ms/step - loss: 0.0407 - accuracy: 0.9569 - val_loss: 0.0728 - val_accuracy: 0.9669\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9552\n",
            "Epoch 00029: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 34s 337ms/step - loss: 0.0434 - accuracy: 0.9552 - val_loss: 0.0713 - val_accuracy: 0.9448\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9531\n",
            "Epoch 00030: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 34s 344ms/step - loss: 0.0428 - accuracy: 0.9531 - val_loss: 0.0796 - val_accuracy: 0.9503\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9541\n",
            "Epoch 00031: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 36s 355ms/step - loss: 0.0421 - accuracy: 0.9541 - val_loss: 0.0764 - val_accuracy: 0.9558\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9571\n",
            "Epoch 00032: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 34s 338ms/step - loss: 0.0365 - accuracy: 0.9571 - val_loss: 0.0697 - val_accuracy: 0.9558\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9616\n",
            "Epoch 00033: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 33s 334ms/step - loss: 0.0391 - accuracy: 0.9616 - val_loss: 0.0535 - val_accuracy: 0.9779\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9635\n",
            "Epoch 00034: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 34s 336ms/step - loss: 0.0347 - accuracy: 0.9635 - val_loss: 0.0492 - val_accuracy: 0.9558\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9539\n",
            "Epoch 00035: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 34s 337ms/step - loss: 0.0454 - accuracy: 0.9539 - val_loss: 0.0810 - val_accuracy: 0.9448\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9542\n",
            "Epoch 00036: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 33s 332ms/step - loss: 0.0401 - accuracy: 0.9542 - val_loss: 0.0491 - val_accuracy: 0.9779\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9621\n",
            "Epoch 00037: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 34s 337ms/step - loss: 0.0372 - accuracy: 0.9621 - val_loss: 0.1190 - val_accuracy: 0.9392\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9627\n",
            "Epoch 00038: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 33s 333ms/step - loss: 0.0379 - accuracy: 0.9627 - val_loss: 0.0745 - val_accuracy: 0.9613\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9614\n",
            "Epoch 00039: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 34s 341ms/step - loss: 0.0377 - accuracy: 0.9614 - val_loss: 0.0474 - val_accuracy: 0.9558\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9595\n",
            "Epoch 00040: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 34s 340ms/step - loss: 0.0384 - accuracy: 0.9595 - val_loss: 0.0581 - val_accuracy: 0.9503\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9631\n",
            "Epoch 00041: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.0352 - accuracy: 0.9631 - val_loss: 0.0957 - val_accuracy: 0.9503\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9629\n",
            "Epoch 00042: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 33s 334ms/step - loss: 0.0340 - accuracy: 0.9629 - val_loss: 0.0676 - val_accuracy: 0.9448\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9592\n",
            "Epoch 00043: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.0404 - accuracy: 0.9592 - val_loss: 0.0596 - val_accuracy: 0.9613\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9644\n",
            "Epoch 00044: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 34s 336ms/step - loss: 0.0320 - accuracy: 0.9644 - val_loss: 0.1122 - val_accuracy: 0.9448\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9631\n",
            "Epoch 00045: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 33s 334ms/step - loss: 0.0312 - accuracy: 0.9631 - val_loss: 0.0543 - val_accuracy: 0.9558\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9651\n",
            "Epoch 00046: val_loss did not improve from 0.03493\n",
            "100/100 [==============================] - 34s 343ms/step - loss: 0.0325 - accuracy: 0.9651 - val_loss: 0.1796 - val_accuracy: 0.9392\n",
            "Epoch 00046: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVvv6F6t8txW",
        "colab_type": "code",
        "outputId": "a3222f79-625c-4da7-ea0a-60c3e3e73a8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history_vgg16_fine_tuned.history['accuracy'])\n",
        "plt.plot(history_vgg16_fine_tuned.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_vgg16_fine_tuned.history['loss'])\n",
        "plt.plot(history_vgg16_fine_tuned.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'lower left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCH_h0uE8x0q",
        "colab_type": "code",
        "outputId": "052d4685-54bb-4973-c499-de14cc0d4688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "validation_loss_vgg16_ft, validation_acc_vgg16_ft = vgg16_fine_tuned_model.evaluate( validation_genrator_VGG16_ft, steps=20, verbose=1)\n",
        "print( 'validation_acc:', validation_acc_vgg16_ft)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    116/Unknown - 52s 444ms/step - loss: 0.1796 - accuracy: 0.9392"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-68001ad2c114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidation_loss_vgg16_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_acc_vgg16_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg16_fine_tuned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mvalidation_genrator_VGG16_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'validation_acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_acc_vgg16_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1082\u001b[0m                 step_num=step):\n\u001b[1;32m   1083\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LBC_N9E9FIQ",
        "colab_type": "code",
        "outputId": "6323ab32-3bdf-479b-ec52-a02d2cc3f927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "test_loss_aug_vgg16_ft, test_acc_vgg_16_ft = vgg16_fine_tuned_model.evaluate(test_generator_VGG16_ft, steps=30)\n",
        "print(test_acc_vgg_16_ft)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 12s 398ms/step - loss: 0.0813 - accuracy: 0.9591\n",
            "0.9590643048286438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGzlmbHv98lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "densenet_ft = DenseNet121(weights='imagenet', include_top=False, input_shape=(140,90,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwOhTOTbXp2Y",
        "colab_type": "code",
        "outputId": "f4e43039-ebbd-4b2b-a44b-91c77909f755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "densenet_ft.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 140, 90, 3)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 146, 96, 3)   0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 70, 45, 64)   9408        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 70, 45, 64)   256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 70, 45, 64)   0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 72, 47, 64)   0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 35, 23, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 35, 23, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 35, 23, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 35, 23, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 35, 23, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 35, 23, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 35, 23, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 35, 23, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 35, 23, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 35, 23, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 35, 23, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 35, 23, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 35, 23, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 35, 23, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 35, 23, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 35, 23, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 35, 23, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 35, 23, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 35, 23, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 35, 23, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 35, 23, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 35, 23, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 35, 23, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 35, 23, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 35, 23, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 35, 23, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 35, 23, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 35, 23, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 35, 23, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 35, 23, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 35, 23, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 35, 23, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 35, 23, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 17, 11, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 17, 11, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 17, 11, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 17, 11, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 17, 11, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 17, 11, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 17, 11, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 17, 11, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 17, 11, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 17, 11, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 17, 11, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 17, 11, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 17, 11, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 17, 11, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 17, 11, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 17, 11, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 17, 11, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 17, 11, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 17, 11, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 17, 11, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 17, 11, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 17, 11, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 17, 11, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 17, 11, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 17, 11, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 17, 11, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 17, 11, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 17, 11, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 17, 11, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 17, 11, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 17, 11, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 17, 11, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 17, 11, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 17, 11, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 17, 11, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 17, 11, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 17, 11, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 17, 11, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 17, 11, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 17, 11, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 17, 11, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 17, 11, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 17, 11, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 17, 11, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 17, 11, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 17, 11, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 17, 11, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 17, 11, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 17, 11, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 17, 11, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 17, 11, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 17, 11, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 17, 11, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 17, 11, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 17, 11, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 17, 11, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 17, 11, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 17, 11, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 17, 11, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 17, 11, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 17, 11, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 8, 5, 256)    0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 8, 5, 256)    1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 8, 5, 256)    0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 8, 5, 128)    32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 8, 5, 128)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 8, 5, 288)    0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 8, 5, 288)    1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 8, 5, 288)    0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 8, 5, 128)    36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 8, 5, 128)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 8, 5, 320)    0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 8, 5, 320)    1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 8, 5, 320)    0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 8, 5, 128)    40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 8, 5, 128)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 8, 5, 352)    0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 8, 5, 352)    1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 8, 5, 352)    0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 8, 5, 128)    45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 8, 5, 128)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 8, 5, 384)    0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 8, 5, 384)    1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 8, 5, 384)    0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 8, 5, 128)    49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 8, 5, 128)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 8, 5, 416)    0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 8, 5, 416)    1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 8, 5, 416)    0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 8, 5, 128)    53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 8, 5, 128)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 8, 5, 448)    0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 8, 5, 448)    1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 8, 5, 448)    0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 8, 5, 128)    57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 8, 5, 128)    0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 8, 5, 480)    0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 8, 5, 480)    1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 8, 5, 480)    0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 8, 5, 128)    61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 8, 5, 128)    0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 8, 5, 512)    0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 8, 5, 512)    2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 8, 5, 512)    0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 8, 5, 128)    65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 8, 5, 128)    0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 8, 5, 544)    0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 8, 5, 544)    2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 8, 5, 544)    0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 8, 5, 128)    69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 8, 5, 576)    0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 8, 5, 576)    2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 8, 5, 576)    0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 8, 5, 128)    73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 8, 5, 608)    0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 8, 5, 608)    2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 8, 5, 608)    0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 8, 5, 128)    77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 8, 5, 640)    0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 8, 5, 640)    2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 8, 5, 640)    0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 8, 5, 128)    81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 8, 5, 672)    0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 8, 5, 672)    2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 8, 5, 672)    0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 8, 5, 128)    86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 8, 5, 704)    0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 8, 5, 704)    2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 8, 5, 704)    0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 8, 5, 128)    90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 8, 5, 736)    0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 8, 5, 736)    2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 8, 5, 736)    0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 8, 5, 128)    94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 8, 5, 768)    0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 8, 5, 768)    3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 8, 5, 768)    0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 8, 5, 128)    98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 8, 5, 800)    0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 8, 5, 800)    3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 8, 5, 800)    0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 8, 5, 128)    102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 8, 5, 832)    0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 8, 5, 832)    3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 8, 5, 832)    0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 8, 5, 128)    106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 8, 5, 864)    0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 8, 5, 864)    3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 8, 5, 864)    0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 8, 5, 128)    110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 8, 5, 896)    0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 8, 5, 896)    3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 8, 5, 896)    0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 8, 5, 128)    114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 8, 5, 928)    0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 8, 5, 928)    3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 8, 5, 928)    0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 8, 5, 128)    118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 8, 5, 960)    0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 8, 5, 960)    3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 8, 5, 960)    0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 8, 5, 128)    122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 8, 5, 992)    0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 8, 5, 992)    3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 8, 5, 992)    0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 8, 5, 128)    126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 8, 5, 1024)   0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 8, 5, 1024)   4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 8, 5, 1024)   0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 8, 5, 512)    524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 4, 2, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 4, 2, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 4, 2, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 4, 2, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 4, 2, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 4, 2, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 4, 2, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 4, 2, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 4, 2, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 4, 2, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 4, 2, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 4, 2, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 4, 2, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 4, 2, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 4, 2, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 4, 2, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 4, 2, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 4, 2, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 4, 2, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 4, 2, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 4, 2, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 4, 2, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 4, 2, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 4, 2, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 4, 2, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 4, 2, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 4, 2, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 4, 2, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 4, 2, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 4, 2, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 4, 2, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 4, 2, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 4, 2, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 4, 2, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 4, 2, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 4, 2, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 4, 2, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 4, 2, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 4, 2, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 4, 2, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 4, 2, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 4, 2, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 4, 2, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 4, 2, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 4, 2, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 4, 2, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 4, 2, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 4, 2, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 4, 2, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 4, 2, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 4, 2, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 4, 2, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 4, 2, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 4, 2, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 4, 2, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 4, 2, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 4, 2, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 4, 2, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 4, 2, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 4, 2, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 4, 2, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 4, 2, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 4, 2, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 4, 2, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 4, 2, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 4, 2, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 4, 2, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 4, 2, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 4, 2, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 4, 2, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 4, 2, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 4, 2, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 4, 2, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 4, 2, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 4, 2, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 4, 2, 1024)   0           bn[0][0]                         \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 6,953,856\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UglSdbr7XubC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "densenet_ft.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in densenet_ft.layers:\n",
        "  if layer.name == 'conv5_block16_1_conv':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-WxwzSQX0Kp",
        "colab_type": "code",
        "outputId": "0e911aad-0561-46fd-b1a6-bf329dc9255e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "train_datagen_dense_ft = ImageDataGenerator(rotation_range=40,\n",
        "                               width_shift_range=0.4,\n",
        "                               height_shift_range=0.4,\n",
        "                               shear_range=0.4,\n",
        "                               zoom_range=0.4,\n",
        "                               horizontal_flip=True,\n",
        "                               rescale=1./255,\n",
        "                               fill_mode='nearest')\n",
        "\n",
        "validation_datagen_dense_ft = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen_dense_ft = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator_dense_ft = train_datagen_dense_ft.flow_from_directory(Train_dir,\n",
        "                                                    target_size = (140, 90),\n",
        "                                                    batch_size = 50,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    shuffle=True\n",
        "                                                    )\n",
        "\n",
        "validation_genrator_dense_ft = validation_datagen_dense_ft.flow_from_directory(Valid_dir, \n",
        "                                                   target_size=(140, 90),\n",
        "                                                   batch_size = 181,\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=True)\n",
        " \n",
        "test_generator_dense_ft = test_datagen_dense_ft.flow_from_directory(Test_dir, \n",
        "                                                  target_size = (140, 90),\n",
        "                                                  batch_size = 171 ,\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 788 images belonging to 6 classes.\n",
            "Found 181 images belonging to 6 classes.\n",
            "Found 171 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLVINevnX_2u",
        "colab_type": "code",
        "outputId": "bdb316f7-6929-45d7-83ee-c46f8909223a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "K.clear_session()\n",
        "denseNet_model_ft = models.Sequential()\n",
        "denseNet_model_ft.add(densenet_ft)\n",
        "denseNet_model_ft.add(layers.Flatten())\n",
        "denseNet_model_ft.add(layers.Dense(256, activation='relu'))\n",
        "denseNet_model_ft.add(layers.Dense(6, activation='sigmoid'))\n",
        "\n",
        "densenet.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 140, 90, 3)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 146, 96, 3)   0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 70, 45, 64)   9408        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 70, 45, 64)   256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 70, 45, 64)   0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 72, 47, 64)   0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 35, 23, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 35, 23, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 35, 23, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 35, 23, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 35, 23, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 35, 23, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 35, 23, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 35, 23, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 35, 23, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 35, 23, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 35, 23, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 35, 23, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 35, 23, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 35, 23, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 35, 23, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 35, 23, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 35, 23, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 35, 23, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 35, 23, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 35, 23, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 35, 23, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 35, 23, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 35, 23, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 35, 23, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 35, 23, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 35, 23, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 35, 23, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 35, 23, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 35, 23, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 35, 23, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 35, 23, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 35, 23, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 35, 23, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 35, 23, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 35, 23, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 17, 11, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 17, 11, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 17, 11, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 17, 11, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 17, 11, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 17, 11, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 17, 11, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 17, 11, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 17, 11, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 17, 11, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 17, 11, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 17, 11, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 17, 11, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 17, 11, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 17, 11, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 17, 11, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 17, 11, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 17, 11, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 17, 11, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 17, 11, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 17, 11, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 17, 11, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 17, 11, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 17, 11, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 17, 11, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 17, 11, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 17, 11, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 17, 11, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 17, 11, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 17, 11, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 17, 11, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 17, 11, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 17, 11, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 17, 11, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 17, 11, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 17, 11, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 17, 11, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 17, 11, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 17, 11, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 17, 11, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 17, 11, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 17, 11, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 17, 11, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 17, 11, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 17, 11, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 17, 11, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 17, 11, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 17, 11, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 17, 11, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 17, 11, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 17, 11, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 17, 11, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 17, 11, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 17, 11, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 17, 11, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 17, 11, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 17, 11, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 17, 11, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 17, 11, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 17, 11, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 17, 11, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 17, 11, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 17, 11, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 17, 11, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 17, 11, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 17, 11, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 8, 5, 256)    0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 8, 5, 256)    1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 8, 5, 256)    0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 8, 5, 128)    32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 8, 5, 128)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 8, 5, 288)    0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 8, 5, 288)    1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 8, 5, 288)    0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 8, 5, 128)    36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 8, 5, 128)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 8, 5, 320)    0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 8, 5, 320)    1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 8, 5, 320)    0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 8, 5, 128)    40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 8, 5, 128)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 8, 5, 352)    0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 8, 5, 352)    1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 8, 5, 352)    0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 8, 5, 128)    45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 8, 5, 128)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 8, 5, 384)    0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 8, 5, 384)    1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 8, 5, 384)    0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 8, 5, 128)    49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 8, 5, 128)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 8, 5, 416)    0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 8, 5, 416)    1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 8, 5, 416)    0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 8, 5, 128)    53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 8, 5, 128)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 8, 5, 448)    0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 8, 5, 448)    1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 8, 5, 448)    0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 8, 5, 128)    57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 8, 5, 128)    0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 8, 5, 480)    0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 8, 5, 480)    1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 8, 5, 480)    0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 8, 5, 128)    61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 8, 5, 128)    0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 8, 5, 512)    0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 8, 5, 512)    2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 8, 5, 512)    0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 8, 5, 128)    65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 8, 5, 128)    512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 8, 5, 128)    0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 8, 5, 32)     36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 8, 5, 544)    0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 8, 5, 544)    2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 8, 5, 544)    0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 8, 5, 128)    69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 8, 5, 576)    0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 8, 5, 576)    2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 8, 5, 576)    0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 8, 5, 128)    73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 8, 5, 608)    0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 8, 5, 608)    2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 8, 5, 608)    0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 8, 5, 128)    77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 8, 5, 640)    0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 8, 5, 640)    2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 8, 5, 640)    0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 8, 5, 128)    81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 8, 5, 672)    0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 8, 5, 672)    2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 8, 5, 672)    0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 8, 5, 128)    86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 8, 5, 704)    0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 8, 5, 704)    2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 8, 5, 704)    0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 8, 5, 128)    90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 8, 5, 736)    0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 8, 5, 736)    2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 8, 5, 736)    0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 8, 5, 128)    94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 8, 5, 768)    0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 8, 5, 768)    3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 8, 5, 768)    0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 8, 5, 128)    98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 8, 5, 800)    0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 8, 5, 800)    3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 8, 5, 800)    0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 8, 5, 128)    102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 8, 5, 832)    0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 8, 5, 832)    3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 8, 5, 832)    0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 8, 5, 128)    106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 8, 5, 864)    0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 8, 5, 864)    3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 8, 5, 864)    0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 8, 5, 128)    110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 8, 5, 896)    0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 8, 5, 896)    3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 8, 5, 896)    0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 8, 5, 128)    114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 8, 5, 928)    0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 8, 5, 928)    3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 8, 5, 928)    0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 8, 5, 128)    118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 8, 5, 960)    0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 8, 5, 960)    3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 8, 5, 960)    0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 8, 5, 128)    122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 8, 5, 992)    0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 8, 5, 992)    3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 8, 5, 992)    0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 8, 5, 128)    126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 8, 5, 128)    512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 8, 5, 128)    0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 8, 5, 32)     36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 8, 5, 1024)   0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 8, 5, 1024)   4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 8, 5, 1024)   0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 8, 5, 512)    524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 4, 2, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 4, 2, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 4, 2, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 4, 2, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 4, 2, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 4, 2, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 4, 2, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 4, 2, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 4, 2, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 4, 2, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 4, 2, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 4, 2, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 4, 2, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 4, 2, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 4, 2, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 4, 2, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 4, 2, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 4, 2, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 4, 2, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 4, 2, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 4, 2, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 4, 2, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 4, 2, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 4, 2, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 4, 2, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 4, 2, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 4, 2, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 4, 2, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 4, 2, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 4, 2, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 4, 2, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 4, 2, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 4, 2, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 4, 2, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 4, 2, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 4, 2, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 4, 2, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 4, 2, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 4, 2, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 4, 2, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 4, 2, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 4, 2, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 4, 2, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 4, 2, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 4, 2, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 4, 2, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 4, 2, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 4, 2, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 4, 2, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 4, 2, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 4, 2, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 4, 2, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 4, 2, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 4, 2, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 4, 2, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 4, 2, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 4, 2, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 4, 2, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 4, 2, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 4, 2, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 4, 2, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 4, 2, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 4, 2, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 4, 2, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 4, 2, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 4, 2, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 4, 2, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 4, 2, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 4, 2, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 4, 2, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 4, 2, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 4, 2, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 4, 2, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 4, 2, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 4, 2, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 4, 2, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 4, 2, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 4, 2, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 4, 2, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 4, 2, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 4, 2, 1024)   0           bn[0][0]                         \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,037,504\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzU1xsZfbzd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback_5 = ModelCheckpoint(filepath = 'my_best_model.hdf7', monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "callback_6 = EarlyStopping(monitor='val_loss', mode='min', patience=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezgClq1Eb4K9",
        "colab_type": "code",
        "outputId": "80eee753-d9e7-4ea7-f80b-c4e916476435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "denseNet_model_ft.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_dense_ft = denseNet_model_ft.fit_generator(train_generator_dense_ft, \n",
        "                                    steps_per_epoch=100,\n",
        "                                    epochs=100,\n",
        "                                    callbacks=[callback_5, callback_6],\n",
        "                                    validation_data=validation_genrator_dense_ft,\n",
        "                                    validation_steps=valid_images.shape[0] / 10\n",
        "                                  )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.7403\n",
            "Epoch 00001: val_loss improved from inf to 0.07418, saving model to my_best_model.hdf7\n",
            "100/100 [==============================] - 37s 368ms/step - loss: 0.2666 - accuracy: 0.7403 - val_loss: 0.0742 - val_accuracy: 0.9337\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.8963\n",
            "Epoch 00002: val_loss improved from 0.07418 to 0.04913, saving model to my_best_model.hdf7\n",
            "100/100 [==============================] - 34s 337ms/step - loss: 0.0991 - accuracy: 0.8963 - val_loss: 0.0491 - val_accuracy: 0.9558\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9164\n",
            "Epoch 00003: val_loss improved from 0.04913 to 0.03187, saving model to my_best_model.hdf7\n",
            "100/100 [==============================] - 34s 335ms/step - loss: 0.0783 - accuracy: 0.9164 - val_loss: 0.0319 - val_accuracy: 0.9724\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9298\n",
            "Epoch 00004: val_loss did not improve from 0.03187\n",
            "100/100 [==============================] - 33s 329ms/step - loss: 0.0644 - accuracy: 0.9298 - val_loss: 0.0813 - val_accuracy: 0.9282\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9316\n",
            "Epoch 00005: val_loss did not improve from 0.03187\n",
            "100/100 [==============================] - 34s 336ms/step - loss: 0.0635 - accuracy: 0.9316 - val_loss: 0.0440 - val_accuracy: 0.9503\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9409\n",
            "Epoch 00006: val_loss did not improve from 0.03187\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.0539 - accuracy: 0.9409 - val_loss: 0.0446 - val_accuracy: 0.9503\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9438\n",
            "Epoch 00007: val_loss did not improve from 0.03187\n",
            "100/100 [==============================] - 35s 347ms/step - loss: 0.0499 - accuracy: 0.9438 - val_loss: 0.0370 - val_accuracy: 0.9613\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.9491\n",
            "Epoch 00008: val_loss did not improve from 0.03187\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.0436 - accuracy: 0.9491 - val_loss: 0.0383 - val_accuracy: 0.9613\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9511\n",
            "Epoch 00009: val_loss did not improve from 0.03187\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.0445 - accuracy: 0.9511 - val_loss: 0.0594 - val_accuracy: 0.9392\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9489\n",
            "Epoch 00010: val_loss did not improve from 0.03187\n",
            "100/100 [==============================] - 33s 329ms/step - loss: 0.0467 - accuracy: 0.9489 - val_loss: 0.0613 - val_accuracy: 0.9503\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9584\n",
            "Epoch 00011: val_loss did not improve from 0.03187\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.0383 - accuracy: 0.9584 - val_loss: 0.0438 - val_accuracy: 0.9613\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9528\n",
            "Epoch 00012: val_loss did not improve from 0.03187\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.0426 - accuracy: 0.9528 - val_loss: 0.0629 - val_accuracy: 0.9392\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9558\n",
            "Epoch 00013: val_loss improved from 0.03187 to 0.02931, saving model to my_best_model.hdf7\n",
            "100/100 [==============================] - 33s 335ms/step - loss: 0.0393 - accuracy: 0.9558 - val_loss: 0.0293 - val_accuracy: 0.9779\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9629\n",
            "Epoch 00014: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 34s 345ms/step - loss: 0.0353 - accuracy: 0.9629 - val_loss: 0.0440 - val_accuracy: 0.9613\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9633\n",
            "Epoch 00015: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 328ms/step - loss: 0.0336 - accuracy: 0.9633 - val_loss: 0.0472 - val_accuracy: 0.9503\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9571\n",
            "Epoch 00016: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.0386 - accuracy: 0.9571 - val_loss: 0.0358 - val_accuracy: 0.9724\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9647\n",
            "Epoch 00017: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 334ms/step - loss: 0.0321 - accuracy: 0.9647 - val_loss: 0.0458 - val_accuracy: 0.9724\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9588\n",
            "Epoch 00018: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.0354 - accuracy: 0.9588 - val_loss: 0.0573 - val_accuracy: 0.9558\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9584\n",
            "Epoch 00019: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.0387 - accuracy: 0.9584 - val_loss: 0.0522 - val_accuracy: 0.9558\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9614\n",
            "Epoch 00020: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.0330 - accuracy: 0.9614 - val_loss: 0.0507 - val_accuracy: 0.9558\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9679\n",
            "Epoch 00021: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 332ms/step - loss: 0.0289 - accuracy: 0.9679 - val_loss: 0.0612 - val_accuracy: 0.9558\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9659\n",
            "Epoch 00022: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 328ms/step - loss: 0.0302 - accuracy: 0.9659 - val_loss: 0.0468 - val_accuracy: 0.9669\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9692\n",
            "Epoch 00023: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 34s 340ms/step - loss: 0.0297 - accuracy: 0.9692 - val_loss: 0.0434 - val_accuracy: 0.9558\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9723\n",
            "Epoch 00024: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 334ms/step - loss: 0.0271 - accuracy: 0.9723 - val_loss: 0.0409 - val_accuracy: 0.9669\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9661\n",
            "Epoch 00025: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 332ms/step - loss: 0.0296 - accuracy: 0.9661 - val_loss: 0.0446 - val_accuracy: 0.9613\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9641\n",
            "Epoch 00026: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 34s 343ms/step - loss: 0.0336 - accuracy: 0.9641 - val_loss: 0.0583 - val_accuracy: 0.9503\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9708\n",
            "Epoch 00027: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 329ms/step - loss: 0.0254 - accuracy: 0.9708 - val_loss: 0.0422 - val_accuracy: 0.9779\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9707\n",
            "Epoch 00028: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.0276 - accuracy: 0.9707 - val_loss: 0.0660 - val_accuracy: 0.9392\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9708\n",
            "Epoch 00029: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.0258 - accuracy: 0.9708 - val_loss: 0.0513 - val_accuracy: 0.9669\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9669\n",
            "Epoch 00030: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 332ms/step - loss: 0.0311 - accuracy: 0.9669 - val_loss: 0.0706 - val_accuracy: 0.9558\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9746\n",
            "Epoch 00031: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 333ms/step - loss: 0.0239 - accuracy: 0.9746 - val_loss: 0.0561 - val_accuracy: 0.9724\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9693\n",
            "Epoch 00032: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.0298 - accuracy: 0.9693 - val_loss: 0.0373 - val_accuracy: 0.9613\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9694\n",
            "Epoch 00033: val_loss did not improve from 0.02931\n",
            "100/100 [==============================] - 34s 342ms/step - loss: 0.0274 - accuracy: 0.9694 - val_loss: 0.0538 - val_accuracy: 0.9448\n",
            "Epoch 00033: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydl9aLYWcJSy",
        "colab_type": "code",
        "outputId": "43f68b4c-83b2-4969-c334-5a23cb803178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "plt.plot(history_dense_ft.history['accuracy'])\n",
        "plt.plot(history_dense_ft.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_dense_ft.history['loss'])\n",
        "plt.plot(history_dense_ft.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc = 'lower left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sfDTlN0cRi7",
        "colab_type": "code",
        "outputId": "cc55ba7e-0ad7-4949-c5ff-5f2090fc1b15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "validation_loss_dense_ft, validation_acc_dense_ft = denseNet_model_ft.evaluate( validation_genrator_dense_ft, steps=20, verbose=1)\n",
        "print( 'validation_acc:', validation_acc_dense_ft)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 7s 330ms/step - loss: 0.0538 - accuracy: 0.9448\n",
            "validation_acc: 0.9447513818740845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQD4AhZ0cVfC",
        "colab_type": "code",
        "outputId": "497b788a-edaf-4925-bc72-6716872a34a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "test_loss_dense_ft, test_acc_dense_ft = denseNet_model_ft.evaluate(test_generator_dense_ft, steps=30)\n",
        "print(test_acc_dense_ft)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 10s 317ms/step - loss: 0.0832 - accuracy: 0.9357\n",
            "0.9356725215911865\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}